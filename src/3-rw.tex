\chapter{Related Work}
\label{cha:rw}

\headerblock{
  \headerquote{
  The sequence is represented by a function called a \emph{stream}, which is a functional analog of a coroutine\ldots}{William H. Burge, 1975~\cite{burge1975stream}}
  % The conventional while and for loops of structured programming may be composed by a technique of stream processing (analogous to list processing), which results in more structured programs than the originals.
  % This technique makes it possible to structure a program in a natural way into its logically separate parts, which can then be considered independently.

  \headerbreak{}

  \headerquote{Stream processing research, in particular the study of SPSs, can be traced back at least as far as the 1960s, although not always in a form that is immediately recognizable as such today.}{Robert Stephens, 1997~\cite{stephens1997survey}}

  \headerbreak{}

  \headerquote{Of course, the notion of a stream as a programming abstraction has been around for decades...}{Thies, Karczmarek, and Amarasinghe, 2002~\cite{thies2002streamit}}
}

While the previous section discussed the primary programming paradigm in current use for distributed streams and its limitations, this section provides a more general survey of related work. We include dataflow programming paradigms, considered broadly; correctness support for both stream and batch data-processing; and the study of partially ordered traces in concurrency theory. We also survey other paradigms related to streaming (functional reactive programming, concurrent and distributed programming, state machines for streaming, and runtime monitoring). Finally, we include a non-exhaustive list of research on systems problems (distribution, parallelization, optimization, benchmarking, and profiling).

\section{Dataflow Programming}

\subsection{Distributed Stream Processing Systems}

Applications over streaming data can be implemented using
high-performance, fault tolerant distributed stream processing systems (DSPS), such as
Apache
Flink \cite{Flink2015,Flink2017,Flink},
Storm~\cite{Storm,StormConcepts},
Spark Streaming~\cite{Spark2013,SparkStreaming},
Kafka~\cite{garg2013apache},
Samza~\cite{Samza2017},
Heron~\cite{kulkarni2015twitter-heron,Heron},
and Beam~\cite{Beam};
Timely Dataflow (Naiad)~\cite{Naiad2013,Timely}
and
Differential Dataflow~\cite{mcsherry2013differential};
Microsoft
StreamInsight~\cite{ACGS2011SI}
and Trill~\cite{chandramouli2014trill};
IBM SPL~\cite{HAG2013SPL};
Google MillWheel~\cite{MillWheel} (now replaced by Google Cloud Dataflow);
Amazon Kinesis~\cite{AmazonKinesis};
and early systems such as
Aurora~\cite{Aurora,AuroraWeb},
Borealis~\cite{Borealis,BorealisWeb},
STREAM~\cite{STREAM2004},
and TelegraphCQ~\cite{Telegraph}.\footnote{
  Some relational database systems also support a limited form of streaming;
  for instance, streaming SQL in Apache Calcite~\cite{begoli2018apache,CalciteStreaming} and Streaming Columns in Apache Derby~\cite{DerbyStreaming}.
}
Stream processing is closely related to,
and sometimes synonymous with,
distributed event processing~\cite{DEBS2006}
and complex event processing~\cite{CEP2006}.
See~\cite{babcock2002models} for an early (2002) report on the status of the field.
See also~\cite{stephens1997survey} for an even earlier (1997) report from the perspective of dataflow languages and reactive systems.

The core programming model for DSPS is typically based on dataflow with auto-parallelization, as discussed in~\Cref{cha:background},
and this is the primary point of comparison for this thesis.
However, there are other programming models used for streaming, including
high-level query languages (often based on SQL),
extensions to the dataflow model,
and extensions to stream parallelism and distribution.

\subsection{High-level Query Languages}

High-level query languages for streaming include
CQL~\cite{arasu2003cql,ABW2006CQL},
CACQ~\cite{CACQ},
CEDR~\cite{BGAH2007CEDR},
Streaming SQL~\cite{jain2008towards,begoli2019one},
SamzaSQL~\cite{pathirage2016samzasql},
Structured Streaming~\cite{armbrust2018structured},
and StreamQRE~\cite{StreamQRE}.
These languages have existed since the early history
of streaming research from the databases community~\cite{stonebraker20058}.
They offer the promise of convenience and clean semantics, but they can be expressively limited for some use cases (e.g., the value-barrier example discussed in the introduction), as we discuss in~\citeMain{ppopp22}.
They typically offer type-safety with respect to the relational schema of each stream and determinism with respect to processing order --
though there are cases where determinism is not guaranteed, including some possible implementations of CQL's tuple-based windows where ties must be broken arbitrarily.\footnote{Thank you to Phillip Hilliard for this observation.}
Traditional query languages view streams in the \emph{sequence-of-relations} model popularized by CQL, which is limited in expressiveness compared to general partial orders.
Inherently sequential operators, such as tuple-based windows and interpolation, are awkward in the sequence-of-relations model.

In modern systems, query operators (typically including maps, windows, filters, joins, and aggregates)
are often implemented not as a separate stream management platform but as
operators on top of the core dataflow programming model, which can also support custom stateful processing and where data need not conform to the relational schema viewpoint.
The upshot of this two-layered design is that the parallelism present at the core dataflow programming model level is relevant even for query languages as: (i) it dictates the extent to which streams can be distributed and optimized, and (ii) it forces semantic requirements on the query in case determinism is required, as otherwise distribution will not be semantics-preserving.

\subsection{Traditional Dataflow Networks and Synchronous Languages}

Dataflow programming predates stream processing.
Dataflow programming as a solution to parallel and distributed computing
originated with Kahn Process Networks~\cite{gilles1974semantics} (KPN), a deterministic dataflow model based on the restriction that channels are FIFO queues with blocking reads and non-blocking writes. Today's systems wish to offer on-demand processing and avoid arbitrary buffering, so they typically do not implement the KPN approach for streams.
In addition to general KPNs, one restriction of KPNs has been particularly influential: synchronous dataflow~\cite{lee1987synchronous}, which further restricts the FIFO queues so that a fixed number of items are read and written on each cycle of an operator. StreamIt~\cite{thies2002streamit} shows that the synchronous dataflow restriction enables aggressive optimization and scheduling; it also somewhat alleviates the problem with blocking reads, because the presence or absence of input and output items is always known statically.
Similar to StreamIt,
the work on synchronous languages from the 90s including LUSTRE~\cite{halbwachs1991synchronous} and ESTEREL~\cite{berry1992esterel} (see~\cite{BCEHlGdS2003SL} for an overview) benefits from the assumption of
synchrony.

The problem with traditional synchronous dataflow languages is that they cannot implement operators which produce a non-static number of output items in response to an input -- including the very most basic such operator, \emph{filter}. (The filter operator applied to an input stream discards items that do not match a given predicate.) As a result, the synchronous model is generally considered too restrictive today for general streaming~\cite{schneider2013safe}.

\subsection{Modern Dataflow Languages}

A more modern take on dataflow programming is MapReduce online~\cite{condie2010mapreduce}; this exemplifies the viewpoint that streaming dataflow graphs are like MapReduce operators chained together.
Other works on streaming specifically focusing on the programming model include SPADE~\cite{gedik2008spade} and Brooklet~\cite{soule2010universal}.
SPADE supports a fixed list of useful operators for streams, like tuple-level transformations (map, flat-map, filter), aggregations, and streaming joins or barriers; it also incorporates some punctuation-related operators.
Brooklet is more like imperative programming,
and is extremely general: it allows translations from CQL, StreamIt, and a (non-streaming) MapReduce like language called SawZall~\cite{pike2005interpreting}.
Another non-streaming, but popular, MapReduced-based dataflow language
is FlumeJava~\cite{chambers2010flumejava}.

\subsection{Extensions to the Dataflow Model}

The dataflow model is limited in its ability to express iterative or recursive queries and other queries with periodic synchronization between nodes, leading to various extensions focused on better expressiveness.
Naiad~\cite{Naiad2013,Timely} proposes \emph{timely dataflow} in order
to support iterative computation.
We compare closely with Timely, the implementation of timely dataflow in Rust, in \Cref{cha:distribution}.
In brief, though Timely is very expressive it is also often quite low-level; as a result, it falls short of automatically scaling without high-level design sacrifices (exposing implementation details to the user).
To avoid semantic issues with out-of-order data,
Timely makes a simplifying assumption that all events are unordered. This necessitates extraneous buffering, complicating the programming model in cases where order would be known between events.

As data processing applications are becoming more complex, evolving from
data analytics to general event-driven applications, some stream
processing and database systems are moving from dataflow programming to more
general actor models
\cite{CarboneFKK20,Bernstein19,BernsteinDKM17,Das2018,xu2021move}.
For example, Flink has recently released Stateful Functions,
an actor-based programming model running on top of Flink
\cite{AkhterFK19,StatefulFunctions}.
Actor models are very expressive, but computations need to be implemented manually as
message-passing protocols.

Other extensions to the dataflow model focus on enabling forms of synchronization between nodes or other concurrency control, or communication with external state.
Communication between parallel nodes is disallowed in the usual formulation of dataflow auto-parallelization.
For example, S-Store and TSpoon~\cite{meehan2015s,affetti2020tspoon} extend stream processing systems with online transaction processing, which can implement concurrency control,
and Noria~\cite{gjengset2018noria} and Nova~\cite{zhao2021timestamped} extend stream processing systems with abstractions for operators to access shared state.
Another way to deal with the problem of communication between nodes
is to use \emph{broadcast state}, a low-level messaging mechanism present in
Timely~\cite{BroadcastStateTimely} and Flink~\cite{BroadcastStateFlink}
which lets one node broadcast a message to all other parallel nodes.
We discuss our alternative solution to all of these issues related to concurrency and synchronization in \Cref{cha:distribution}.
In brief, our model avoids sacrificing high-level design by making the distribution of a program independent of the programming model; we guarantee that, subject to an assumption that the the program satisfies some consistency conditions, the implementation is deterministic.

\subsection{Summary}

In all of the existing works on dataflow surveyed, streams are typed at a coarse-grained level: typically, only using a construct such as \texttt{Stream<T>} for a stream of events of type \texttt{T}, and not encoding the possible parallelization.
Some languages include a few variants, such as Flink's \texttt{KeyedStream} which is parallelized by key, and CQL's distinction between streams \texttt{Stream<T>} and time-series relations \texttt{Relation<T>} which are created from streams using windowing operators.
Compared to coarse-grained stream types, fine-grained stream types
record additional parallelization information and describe the possible parallelization at the system level, the dataflow model level, or at the query language level.
% can be seen as a way to record parallelization information across the software stack, whether at the
% For example, in \Cref{cha:distribution} we pass types from the distributed programming model to the distributed runtime and use them to implement automatic safe distribution.
% The original version of \Cref{cha:foundation}'s type system in~\citeMain{pods21} was inspired by database schema types at the query language level.

\section{Correctness Support for Data-Parallel Programs}

\subsection{Testing}

Many previous works focus on batch processing programs written in the MapReduce~\cite{dean2008mapreduce} framework \cite{csallner2011new,xu2013semantic,marynowski2012testing,chen2016commutativity} (see also the recent survey \cite{moran2019testing}).
Some work~\cite{xu2013testing} goes beyond batch processing to study testing semantic properties of operators in general dataflow or stream-processing programs.
One limitation of many of these works \cite{csallner2011new,xu2013semantic,xu2013testing,chen2016commutativity} is that real-world MapReduce programs (and, by extension, aggregators in stream processing programs) can be non-commutative: the empirical study at Microsoft~\cite{xiao2014nondeterminism} reports that about 58\% of 507 user-written reduce jobs are non-commutative, and that most of these are most likely not buggy.
The previous work on testing would erroneously flag these programs as containing bugs due to nondeterminism (false positive).

Differential testing~\cite{mckeeman1998differential,groce2007randomized} is a well-established, lightweight, black-box method to detect bugs in complex programs by simply comparing two programs that are supposed to be equivalent.
In \Cref{cha:testing} (DiffStream), we adopt differential testing to finding bugs due to parallelism with the goal of avoiding the false-positives mentioned in the previous paragraph; we do succeed in avoiding false positives in most cases, though not in a few others where nondeterminism is truly inherent to the computation.

Besides DiffStream, a few other dedicated testing tools for Flink now exist:
Flinkspector~\cite{flinkspector} provides unit testing;
FlinkCheck~\cite{espinosa2019flinkcheck} uses temporal logic for property-based testing; and SPOT~\cite{ye2021spot} uses symbolic execution to improve path coverage.
See also~\cite{joachim2018methodology} for further reading on this topic.

\subsection{Static Verification}

In addition to testing -- a dynamic method of checking
correctness -- there has also been research on the static verification
of data-parallel programs. Recent work focuses on the verification of
parallel aggregators that are used in MapReduce programs; methods include automated verification and synthesis of \emph{partial
aggregators} given an aggregation function~\cite{liu2014automating},
or parallelizing user defined aggregators using symbolic
execution~\cite{raychev2015parallelizing}.

We would be interested if similar ideas could be generalized to the abstractions in this thesis,
rather than just MapReduce programs;
i.e., we would like to verify and synthesize operators in streaming dataflow graphs.
Note that streaming graphs are not always decomposable into aggregators, and their parallel
and sequential implementations might have significant structural
differences (see the Topic Count case study in
\Cref{cha:testing}), implying that the parallel implementation cannot be simply
derived from the sequential implementation.

For general stream processing, \cite{schneider2013safe} has proposed an approach to ensure correct parallelization (deterministic distribution) based on categorizing operators for properties such as statefulness and selectivity.
This is very closely related to our work on guaranteeing type-safe, deterministic distribution;
while it is practical, it could be considered ad hoc to enumerate operators into finitely many categories.
Another complication is if considering streaming graphs that interact with external service (e.g., querying a Redis database) or complex extensions to the dataflow model including operators like broadcast-state.

Instead of verifying user-written streaming programs, one can instead consider the problem of correctness for systems, compilers, and implementations.
Towards testing functional correctness of a stream processing system implementation, a framework has been proposed for Microsoft StreamInsight~\cite{raizman2010extensible}.

Overall, verifying streaming dataflows statically is an important problem for future work which is not yet easily within our reach, and which we discuss further in \Cref{cha:discussion}.

\subsection{Empirical Studies and Debugging}

Complementary to directly establishing the correctness of user-written programs, one can look at the problem of correctness from an empirical and engineering perspective.
There are a number of empirical studies which aim to classify bugs in real-world stream- and batch-processing programs. Of these, most~\cite{schroeder2009large, kavulya2010analysis, li2013characteristic, zhou2015empirical} have primarily focused on sources of job failures (e.g., system crashes) or performance issues (e.g., memory use patterns and computational bottlenecks), which are orthogonal to semantic bugs which can be found by testing. The Microsoft study~\cite{xiao2014nondeterminism} is the only study we are aware of that classifies semantic bugs in user-written programs.
In addition to these studies of data-processing programs, there have been some empirical studies which interview users about their testing and debugging needs. In~\cite{fisher2012interactions}, users of Spark are interviewed about tools that would be useful to them, but the study focuses on \emph{human-computer interaction} needs such as data visualization and debugging tools. The more recent study~\cite{vianna2019exploratory} aims to determine how current specialists in data stream processing applications currently implement testing. Most specialist employ unit and integration testing, together with some techniques and tools for more sophisticated testing (e.g., inducing node failures). Our work is motivated by the need to go beyond these standard techniques to increase confidence in the \emph{semantic correctness} of user-written programs, especially in the presence of parallelism and out-of-order data.

Empirical studies also motivate important work on visualization and debugging.
Visualization includes generating example inputs for dataflow programs showcasing typical semantic behavior~\cite{olston2009generating}. Debugging includes, e.g., setting up breakpoints, stepping through computations, and determining crash culprits~\cite{gulzar2016bigdebug,olston2011inspector}.

\section{Partially Ordered Trace Theory}

\subsection{Mazurkiewicz Traces}

Our type system builds on foundational work in concurrency theory dating back to Mazurkiewicz \cite{mazurkiewicz1986trace}, where partially ordered sets of events are called \emph{Mazurkiewicz traces}. Mazurkiewicz traces have been studied from the viewpoints of algebra, combinatorics, formal languages and automata, and
logic \cite{DiekertR1995}. In practical applications to verification and
testing of concurrent systems, they appear for example in relation to
\emph{partial order reduction}~\cite{God96,Peled94}, a technique for
pruning the search space of possible execution sequences.

Mazurkiewicz traces correspond to the view of streams as linearizations and as labeled partially ordered sets (see \Cref{cha:foundation}),
traditionally called \emph{partially ordered multisets} (pomsets).
Both of these views and the isomorphism between them are standard and well-known in this literature.
Our type system, however, is an abstraction on top of Mazurkiewicz traces; it
gives rise not to all dependence relations, but only to certain ones that have a series-parallel structure
(see \Cref{prop:stream-types-less-general}).
We believe that the series-parallel streams constitute most useful use cases in practice, where there are usually only perhaps one or two levels of nesting in the type. Most streams consist of events of maybe one or two base types, with punctuation and other system events, and our types aim to cater towards these simpler use cases.

An important technical difference is that in the theory of Mazurkiewicz traces, one usually assumes a finite, symmetric, and reflexive dependence relation~\cite{DiekertR1995}. In contrast, in this thesis, we only require it to be symmetric; it is neither finite (due to arbitrary infinite base-types and key-based parallelism) nor reflexive (due to the relational base type). This is in order to support user-provided dependence relations over a possibly infinite data domain, which is necessary to model common patterns in the streaming setting. Patterns such as this one cannot be captured by a finite alphabet, and this limits the direct application of classical work on concurrency theory over a finite dependence relation.

\subsection{Checking Properties of Traces}

Much classical research has focused on deciding properties of traces such as serializability, linearizability, sequential consistency, and data race detection.
Broadly speaking, these properties are search problems: the algorithm monitors an execution of events, and it must decide if there exists some possible equivalent execution that witnesses the desired property. For example, race detection involves deciding, given a sequence of events, if there is a valid reordering of the events, subject to the constraints imposed by synchronization events, in which two specific events (representing a potential race condition) get reordered. If there are an arbitrary number of threads then race detection is NP-hard~\cite{netzer1990complexity,netzer1992race}
(but it is easy to decide for, say, only two traces and can be done in a streaming manner).
Similarly, checking sequential consistency of a given trace is NP-complete~\cite{gibbons1992complexity},
as is checking linearizability in general~\cite{gibbons1997testing}.
Practical tools for testing correctness of traces (e.g., \cite{savage1997eraser,park2011efficient,sen2008race,wing1993testing,burckhardt2010line,lowe2017testing}) are bound by these results and explore the trade-off between soundness, completeness, and tractability.

In our work we don't generally consider algorithmic problems on traces, with the exception of \Cref{cha:testing},
where we consider the algorithmic problem of checking \emph{equivalence} of two Mazurkiewicz traces (equality of streams up to re-ordering).
As with our type system, we consider this problem for general infinite-alphabet traces, rather than just those over a finite alphabet.
The problem we consider is in PTIME (for the offline variant), admits a space-optimal (though not space-bounded) online monitoring algorithm,
and to our knowledge hasn't been explicitly articulated in existing work on Mazurkiewicz traces.

\section{Other Paradigms}

\subsection{Functional Reactive Programming}

In the functional programming community, researchers have long investigated
\emph{functional reactive programming} (FRP)~\cite{wan2000functional,nilsson2002functional}.
See also~\cite{bainomugisha2013survey} for a survey and~\cite{blackheath2016functional} for an introductory textbook.
FRP is closely related to dataflow and is suitable for streaming.
The earliest work on FRP dates back to the late 1990s, targeted for interactive graphics applications~\cite{elliott1997functional,elliott1997modeling},
but FRP has persistently inspired new formalizations and implementations~\cite{courtney2001frappe,cooper2006embedding,foster2011frenetic,perez2016functional}.
In FRP, streams are mostly sequential objects which are processed incrementally; FRP abstracts both discrete-time and continuous-time signals.
Some research has endeavored to make FRP distributed,
for example by adding mechanisms for
fault tolerance~\cite{perez2020fault},
type-safe clocks~\cite{barenz2018rhine}
and distributed actors~\cite{shibanai2018distributed}.

\subsection{Fork-Join Based Concurrency}

Fork-join based
concurrent programming~\cite{frigo1998implementation,lea2000java}
constitutes a classical parallel programming paradigm,
relevant to \Cref{cha:distribution}.
Fork-join parallel programming models are typically expressive but low-level, and do not guarantee determinism or data-race freedom.
Concurrent revisions~\cite{burckhardt2010concurrent}
guarantees determinism in the presence of concurrent updates
by allowing programmers to declare types to describe how parallel updates are merged on joins.
More generally, a great many proposals exist to make concurrent programming safe (typically not fully deterministic, but at least data-race free);
we do not attempt to survey them all here,
but for a recent example and related work, see fearless concurrency~\cite{milano2022flexible}.

\subsection{Distributed Programming Models and Consistency}

Monotonic lattice-based programming models,
including Conflict-Free Replicated Data Types~\cite{shapiro2011conflict},
Bloom$^L$~\cite{conway12},
and LVars~\cite{lvars13,lvars14},
are designed for coordination-free distributed programming.
These models guarantee strong eventual consistency,
i.e., eventually all replicas will have the same state.
Partially ordered sets are an important concept in this space
because consistency for replicated data stores
often relies on determining which events are unordered and can be
safely executed without coordination,
and which events require global synchronization between nodes.
For some examples of this distinction,
see RedBlue consistency~\cite{li2012making},
MixT~\cite{milano2018mixt},
Gallifrey~\cite{milano2019tour},
Quelea~\cite{sivaramakrishnan2015declarative},
CISE~\cite{gotsman16},
Carol~\cite{lewchenko2019sequential},
Hamband~\cite{houshmand2022hamband},
and Quark~\cite{kaki2022runtime},
all of which support a mix of consistency guarantees on different operations,
effectively inducing a partial order of data store operations.

\subsection{State Machines for Data Processing}

Returning from the distributed to the sequential setting,
next we survey state-machine representations for performance-sensitive
data stream processing, relevant to \Cref{cha:monitoring}.

Deterministic and nondeterministic finite-state automata~\cite{rabin1959finite} are foundational in streaming as they correspond precisely to finite-memory, finite-time-per-element computations. However, they lack the ability to perform \emph{quantitative} computations that aren't finite-state, such as e.g., simply counting the total number of input items.
The simplest studied model of quantitative finite-state computation is
\emph{weighted automata}~\cite{ABK2011WA,DKV2009HWA}, originally defined by Schützenberger \cite{S1961WA}.
Weighted automata extend nondeterministic finite-state automata by annotating transitions with \emph{weights} (which are elements of an abstract semiring) and can be used for the computation of simple quantitative properties, such as counting or summing the input items.
Extensions of weighted automata include \emph{nested weighted automata} \cite{CHO2015NWA}, which allows one level of nesting, and our related work~\citeMain{icalp17}, which generalizes this to arbitrary hierarchical nesting, and was a precursor to data transducers (\citeMain{popl19} and \Cref{cha:monitoring}).
See~\cite{CDH2010QL,CHO2016QMA} for further discussion of quantitative models.
Compared to data transducers, weighted automata support a limited set of operations (addition and multiplication in the semiring), rather than an arbitrary family of data types and operations on them.
And while nested models recover some of this expressiveness, they can be cumbersome to work with.

A second approach to augment classical automata with quantitative features has been with the addition of \emph{registers} that can store values from a potentially infinite set. These models are typically varied in two aspects: by the choice of data types and operations that are allowed for register manipulation, and by the ability to perform tests on the registers for control flow.
The literature on data words, data/register automata, and their associated logics \cite{KF1994FMA, NSV2004FSM, DL2009LFQ, BS2010NRDL, BDMSS2011LDW} (and extensions such as register monitors~\cite{FHS2018}) studies words over an infinite alphabet, typically of the form $(\Sigma \times \mathbb{N})^*$,
where $\Sigma$ is a finite set of tags and $\mathbb{N}$ is the set of the natural numbers.
They allow comparing data values for equality, and these equality tests can affect the control flow.
The work on cost-register automata (CRA)~\cite{AdADRY2013CRA} studies what happens when the control and data registers are kept separate by allowing write access to the registers but no testing.
The register model in cost-register automata originated in streaming transducers~\cite{AC2010SST,AC2011STA,AdA2012STT}.
As discussed in \Cref{dt:subsec:dts-and-cras},
data transducers are expressively equivalent to CRAs, but are exponentially more succinct.
Expressively and in logical terms, both CRAs and data transducers recognize the class of \emph{streamable regular transductions}~\citeMain{tcs20}, which can also be defined by monadic second order logic (MSO) or attribute grammars~\cite{EM1999MTT,BE2000}.

A third extension of automata relevant for quantitative computation is symbolic automata~\cite{d2014minimization,veanes2012symbolic-toolkit} and transducers~\cite{veanes2012symbolic,d2013equivalence};
see \cite{d2021automata} for an introduction.
While symbolic automata do not allow all quantitative computations (e.g., adding up a data word of values), because transitions are predicates on input data, they can express some limited examples.
One problem with weighted automata and register automata is that sometimes may lack closure under sequential composition, because sequential composition can be used to express non-regular properties (see~\cite{StreamQRE}, page 699); e.g., we can add up left and right parentheses to accept the Dyck language, or accept sequences of increasing numbers.
Symbolic automata may be helpful to address this limitation.

\subsection{Runtime Verification and Monitoring}

Our work in \Cref{cha:testing,cha:monitoring} contributes to the large body of work on runtime verification~\cite{leucker2009brief,havelund2004efficient} (also known as \emph{runtime monitoring}), a
lightweight verification paradigm which aims to identify bugs in the
output of a program as it is executed, using minimal computational
resources.
(The testing problem we consider is a runtime verification problem, and
the data transducers work is a language that can be used for monitoring applications.)
In typical work on runtime verification, the problem is to detect
violations of a safety property written in a logical specification language.
The specification is translated into a \emph{monitor}, which executes along with the monitored system: it consumes system events in a streaming manner and outputs the satisfaction or falsification of the specification. \emph{Linear Temporal Logic} (LTL) is the most widely used formalism for describing specifications for monitoring.

LTL is rather limited in expressiveness, but has been extended in various ways,
including quantitative extensions.
Metric Temporal Logic (MTL) has been used for monitoring real-time temporal properties \cite{TR2005MTL}. Signal Temporal Logic (STL), which extends MTL with value comparisons, has been used for monitoring real-valued signals \cite{DDGJJS2017}.
Computing statistical aggregates of LTL-defined properties, as in \cite{finkbeiner2002collecting}, is a limited form of quantitative monitoring.
The Eagle specification language \cite{barringer2004rule} can also express some quantitative monitoring properties, since it supports data-bindings.
Quantitative regular expressions are suitable for quantitative and performance-sensitive monitoring~\cite{QRE,StreamQRE,YLMMAL2017NQRE,AAMMR2018}
and can be compiled to CRAs or data transducers.
Finally, the synchronous languages~\cite{BCEHlGdS2003SL} mentioned earlier can also be used for monitoring quantitative data streams.
LOLA \cite{d2005lola,bozzelli2016foundations} is a notable example of a synchronous language designed for runtime monitoring
with close similarity to state-machine based monitors.
RTLola~\cite{faymonville2017real} extends LOLA to the real-time monitoring setting, rather than synchronous monitoring.

In contrast to classical work in runtime verification and monitoring, our core type system in this thesis models program execution traces as partially rather than totally ordered; our ultimate goal is runtime verification abstractions which work on partially ordered streams, for which \Cref{cha:testing} is an initial proposal, handling the simplest case of equality checks between streams.

\section{Selected Systems Challenges}

On the other side of the programming model,
researchers have proposed distribution, parallelization, optimization, benchmarking, and profiling strategies for stream programs.
These can be relevant to the programming model as they affect the sort of semantic guarantees that the system can offer with respect to parallelism;
however, the primary goal of these works is to enable efficient system implementations.

The literature in these areas is vast; we survey only a subset. We especially focus on papers relevant for \emph{geo-distributed} performance optimization~\citeMain{wpe2}: these aim to enable streaming applications over many distributed nodes that don't necessarily all reside in the same central cluster.
This is especially relevant for IoT applications and edge/fog computing~\cite{satyanarayanan2017emergence,dastjerdi2016fog,shi2016edge,villari2016osmotic} (see also programming models such as Mobile Fog~\cite{hong2013mobile-fog})
and for applications where bandwidth is limited~\cite{vulimiri2015global-analytics,chienchun2018videoedge,zhang2018awstream}.

\subsection{Performance Benchmarking and Profiling}

Towards more fine-tuned optimization, researchers have proposed many techniques for analyzing the performance of existing systems.
In particular, streaming benchmarks are invaluable for comparing across systems.
The Yahoo Streaming Benchmark~\cite{yahoostreaming2016} is widely used,
though outdated in some respects, and has motivated more modern benchmark suites~\cite{bordin2020dspbench,lopez2016performance}.
The DEBS Grand Challenge, an annual contest presented by the DEBS conference~\cite{DEBS2006}, is another useful source of more complex tasks and data.
Performance profiling often centers on detecting performance bottlenecks, called stragglers~\cite{liu2020resource,khan2015empirical}.
SnailTrail exemplifies a state-of-the-art system and technique for latency profiling and straggler detection~\cite{hoffmann2018snailtrail}.

\subsection{Operator Placement}

A fundamental problem in distribution of streaming operators, and closely related to the distribution problem considered in \Cref{cha:distribution},
is \emph{operator placement} where the system determines what node to run a stream operator on.
The work~\cite{cardellini2016optimal} uses constraint solving to optimize operator placement relative to network bandwidth and other constraints.
Other than~\cite{cardellini2016optimal}, there are several lines of work in job scheduling, operator placement, and optimization for DSPS that try to be network-aware in some fashion. Early and influential works include~\cite{ahmad2004network} and~\cite{pietzuch2006network}.
The first~\cite{ahmad2004network} is probably the first to formalize the operator placement problem for DSPS, and to explore (1) how network-awareness can lead to more efficient query evaluation, and (2) how there is a trade-off between latency and bandwidth use in this space.
The second~\cite{pietzuch2006network} presents a simple but effective heuristic algorithm which treats the geo-distributed physical nodes as a system of points in a combined latency-bandwidth space, and uses spring relaxation find a good configuration.
The work~\cite{gu2015general}, similarly to~\cite{cardellini2016optimal}, formulates operator placement as a mixed integer linear program.
There are a number of other related papers on job scheduling~\cite{aniello2013adaptive,xu2014tstorm,eidenbenz2016task,wolf2008soda,fu2019edgewise}, operator placement~\cite{bonfils2004adaptive,tziritas2016improving,rizou2010solving,lakshmanan2008placement},
and resource elasticity~\cite{cardellini2018decentralized,hochreiner2016elastic,cardellini2018optimal,dias2018dsp-survey}.

Researchers have also modified the programming model to allow the programmer to control operator placement.
SpanEdge~\cite{sajjad2016spanedge} is a primitive modification to the dataflow programming model with tasks that should be run globally versus locally.
A system very related to SpanEdge is Geelytics~\cite{cheng2015geelytics}.
It modifies the dataflow programming model with \emph{scoped tasks}, which have a geographic granularity such as by site, by city, by district, or by section, and are similar to SpanEdge's local and global tasks.
Other than these, the paper~\cite{renart2017datadrivenstreamedge} proposes a programming framework for stream processing in a geo-distributed (at the edge) fashion. The programming framework, however, is not based on dataflow, and is more focused on the communication mechanisms between nodes. There is also a large body of work on programming for wireless sensor networks; see the survey~\cite{mottola2011programming-wsn}. In general, the concerns in that domain have been more low-level, related to connections between sensors, mobility of sensors, communication from one sensor to another via short hops, and so on.

\subsection{Stream Degradation}

An even more aggressive technique for optimizing distributed execution is to degrade and approximate streams to reduce what needs to be sent over the network.
The first stream processing system to incorporate general degradation of data streams was JetStream~\cite{rabkin2014jetstream}.
JetStream seeks to limit bandwidth use not just through degradation, but also ``aggregation'', which refers to a data model where data is saved and aggregated by geo-distributed nodes, and only sent when explicitly requested.
AWStream~\cite{zhang2018awstream} uses programming knobs to control the amount of degradation that occurs for video streams (e.g., frame rate reduction, resolution reduction, or some combination) to try to achieve a Pareto-optimal solution between accuracy and bandwidth use. Other systems in this space include WASP~\cite{jonathan2020wasp}.

\emph{Load shedding}~\cite{tatbul2003load,tatbul2007staying} can be seen as a primitive form of stream degradation.
This refers to selectively dropping tuples in response to load that is beyond capacity, in order to maintain availability and good latency while hopefully not losing too much accuracy.
For video data, for instance, load shedding would enable frame rate reduction but would not allow resolution reduction. It is well studied, but less flexible than what is offered by more modern systems like JetStream and AWStream.
