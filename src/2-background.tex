\chapter{Background}
\label{cha:background}
\headerblock{
  \headerquote{The fourth requirement is that a stream processing engine must guarantee predictable and repeatable outcomes.}{Michael Stonebraker, Uğur Çetintemel, and Stan Zdonik in ``\emph{The 8 Requirements of Real-Time Stream Processing}'' (December 2005).~\cite{stonebraker20058}}
}

\begin{table}[tp]
\def\arraystretch{3.7}
\begin{tabular}{c|cccc}
    System & Year & Stable Release & Active? & \makecell{Questions on \\ StackOverflow \\ (as of 2022-06-07)} \\
    \hline
    Aurora
        & 2003~\cite{Aurora} & 2003~\cite{AuroraWeb} & \RedNo{} & -- \\
    Borealis
        & 2005~\cite{Borealis} & 2008~\cite{BorealisWeb} & \RedNo{} & -- \\
    \includegraphics[align=c,width=3.5cm]{img/systems/storm.png}
        & 2011~\cite{StormInitRelease} & 2022~\cite{Storm} & \GreenYes{} & 2564 \\
    \rule{0pt}{11ex} % some extra spacing here
    \makecell{
    \includegraphics[align=c,width=2.5cm]{img/systems/flink.png} \\ \cite{Flink,Flink2015}}
        & 2011 & 2022~\cite{FlinkRelease} & \GreenYes{} & 6428 \\
    Google MillWheel
        & 2013~\cite{MillWheel} & -- & \RedNo{} & -- \\
    \makecell{
      \includegraphics[align=c,width=3.5cm]{img/systems/spark.jpg} \\
      (Apache Spark Streaming)
    }
        & 2013~\cite{Spark2013} & 2022~\cite{SparkStreaming} & \GreenYes{} & 5408 \\
    \makecell{\includegraphics[align=c,width=3.5cm]{img/systems/samza.png} \\ \cite{Samza,Samza2017}}
        & 2013 & 2020~\cite{SamzaRelease} & \GreenYes{} & 81 \\
    Timely Dataflow & 2013~\cite{Naiad2013}
        & 2021~\cite{Timely} & \GreenYes{} & -- \\
    \makecell{\includegraphics[align=c,width=3.5cm]{img/systems/heron.png} \\ \cite{Heron,kulkarni2015twitter-heron}}
        & 2015 & 2021~\cite{HeronRelease} & \GreenYes{} & 43 \\
\end{tabular}

\vspace{0.5cm}

\caption{A selection of major distributed stream processing systems.}
\label{fig:dsps-examples}
\end{table}

\section{Distributed Stream Processing Systems}

Today's de facto programming solution for programming over
distributed streams
is found in \emph{distributed stream processing systems (DSPS)}.
Popular modern DSPS include
Apache Flink~\cite{Flink,Flink2015},
Timely Dataflow~\cite{Timely,Naiad2013},
and Apache Spark Streaming~\cite{SparkStreaming,Spark2013}.
A selection of these and other systems is included in Table~\ref{fig:dsps-examples}.
There are a vast number of DSPS beyond what can be listed here, including many research prototypes as well as actively developed software products in widespread use.
In this chapter, we review the primary defining properties common to DSPS, with a particular focus on the programming model and semantics. We then discuss the limitations of the existing model and systems.

\subsection{Comparison with Batch Processing}

To understand the emergence of DSPS and why traditional software infrastructure
is not sufficient, note that traditional software
is often based on the assumption that
critical data can be stored and then processed later.
For example,
much of large-scale data analytics relies on processing data in large
\emph{batches} (e.g. training a machine learning model daily),
such as via MapReduce jobs~\cite{dean2008mapreduce}.
While batch processing
does take advantage of distributed computing resources,
it does not take advantage of the transient and temporal structure of data.
Data is not transient because it must be stored first,
which introduces costs due to batch sizes and data movement.
In practice due to these costs, most data traveling over the internet
and processed by cloud services is either not stored or not harvested to its full potential.
Additionally, the temporal structure of data is lost in batches, which divide
data at arbitrary boundaries in time.
For example, a machine learning model that might benefit from continuous updates is instead trained only on the data from yesterday.
DSPS offer a software framework for writing such programs, where data processing logic is defined in a platform-independent manner,
then deployed as a distributed application over many nodes.
DSPS performance is measured in terms of \emph{latency} and \emph{throughput},
while batch processing performance is primarily measured in terms of throughput only.
Concretely, stream processing platforms aim for latency in the milliseconds and throughput in tens of thousands of events per process per node.

\section{Commonalities}

While DSPS differ in many substantial ways, all DSPS in current use share the so-called \emph{dataflow programming model.} This means that the programmer writes, in some form or another, a dataflow graph. In some systems, e.g. Apache Storm, the dataflow graph is written out explicitly, whereas in others, such as Apache Flink, the graph is implicit. Additionally, systems may offer high-level libraries for creating or composing dataflow graphs; in particular, these include libraries for complex windowing operations and for SQL- and CQL-based streaming queries.
The dataflow programming model exposes task and pipeline parallelism; to expose additional data parallelism, DSPS use \emph{operator replication}. Similar to how a MapReduce~\cite{dean2008mapreduce} job is implicitly parallelized, all operators in a dataflow grpah (unless configured otherwise) may be split into several copies; this is part of the programming model as well, and affects the semantics.

\subsection{The Dataflow Programming Model}

We introduce the programming model through a simplified example based on a real-time video analytics use case.
Imagine a large-scale system of video cameras, perhaps located in several cities throughout a country. Each video camera produces a stream of video data, at a certain frame rate and image resolution. Suppose that we want to identify pedestrians and report to a central location the summary of all pedestrian activity in the last 10 minutes, i.e., where pedestrians are most active. To do so, we want to classify each image from each camera using an out-of-the-box classifier; then, to prevent noise and to summarize the total activity, we want to aggregate the data from all classifiers in the last 10 minutes in a particular location (e.g., one intersection or group of intersections). In the end, we report for each location the total amount of pedestrian activity. (One could imagine taking further steps, such as adding a smoothing filter which removes reports of pedestrian activity that last only for a single frame, assuming that these must be erroneous.)

A dataflow pipeline for this is given in Figure~\ref{fig:dataflow-example}. The input data consists of raw video data. Notice that the pipeline contains only one operator at each stage; that is, we treat all input data at \emph{all} cameras as a single input stream; and we write transformations over that stream. The first transformation, \texttt{keyBy(deviceID)}, says to divide the stream into substreams for different keys, where each key is a device ID. (Note that in some frameworks, such as Apache Storm, this would not necessarily be an explicit operator in the dataflow, but rather an annotation on the input data streams.) The second transformation, \texttt{classify}, says to process each input data item, which is a video frame, and return the classification ($1$ for a pedestrian, $0$ for no pedestrian). The third transformation is similar to the first, but this time we group by location, instead of by device ID. The final transformation is the sliding window which adds up all the values over the last 10 minutes. This is then output and could be displayed to the user as a real-time report of activity across all locations.

\begin{figure}[t]
\centering
\begin{tikzpicture}[node distance=0.5cm,every node/.style={font=\small}]
\node[source] (in) {input};
\node[operator, right=of in] (op1) {keyBy(deviceID)};
\node[operator, right=of op1] (op2) {classify};
\node[operator, right=of op2] (op3) {keyBy(location)};
\node[operator, right=of op3] (op4) {sliding window \\ (10 min)};
\node[sink, right=of op4] (out) {output};

\draw[dataflowedge] (in) -- (op1);
\draw[dataflowedge] (op1) -- (op2);
\draw[dataflowedge] (op2) -- (op3);
\draw[dataflowedge] (op3) -- (op4);
\draw[dataflowedge] (op4) -- (out);
\end{tikzpicture}

\caption{Example DSP dataflow graph for a program to classify video streams and report total pedestrian activity.}
\label{fig:dataflow-example}
\end{figure}

In general, streaming dataflow graphs are acyclic, although some systems support ways to provide feedback and/or support iterative (cyclic) computations.
The input and output nodes in a dataflow are special, because they interact with the external system, and can usually be of several kinds: e.g. taking input from a distributed file system, taking input from a live stream of data, writing output to a file, or in general interacting with some external service which provides input or consumes output.
It is generally preferred that \emph{internal nodes do not consume input or produce output}; however, that does not mean they are pure; they are often stateful, and may also produce logs, interact with a stored database, etc.
Formally, we summarize a definition of a streaming dataflow graph that is (approximately) common to all DSPS programming models.

\begin{definition}[Streaming Dataflow Graph]
\label{def:dataflow-graph}
An \emph{acyclic streaming dataflow graph} (DSP dataflow graph) consists of a set of input nodes called \emph{sources}, a set of intermediate nodes
called \emph{operators}, and a set of output nodes called \emph{sinks}, connected by a set of
directed edges which are \emph{data streams}.
The nodes and edges form a directed acyclic graph (DAG).
Each source node may produce data items continuously, and each sink node consumes data items.

Operators are possibly stateful streaming functions that describe how to process an input item and when to produce output. They do not get to choose which of their input streams to read from; rather they have an input even handler which can be called on any event when it arrives.
They may produce any number of outputs on any input item, in any combination of output streams.
\end{definition}

The number of output items produced per input item is often called the operator's \emph{selectivity},
which may be e.g. $1$ (for a map), $0-1$ (for a filter), or more than $1$ (for a copy).
The fact that the selectivity is not constant is a major challenge that makes scheduling DSPS applications more difficult.

\subsection{Auto-Parallelization (Operator Replication).}

DSPS rely on three types of parallelization to achieve scalability, especially to achieve high throughput.
The first two are explicitly exposed in any acyclic streaming dataflow graph. \emph{Pipeline parallelism}, which is visible in Figure~\ref{fig:dataflow-example}, means that different operators in a sequential pipeline can be run by different workers, threads, or distributed nodes. \emph{Task parallelism} is not shown in our example, but means that different operators in a parallel set of disjoint tasks (parallel nodes in the dataflow) can be run by different workers, threads, or distributed nodes. However, the arguably most important form of parallelism for huge data sources is \emph{data parallelism}, where different data items in the same input stream are processed by different workers, threads, or distributed nodes.
DSPS use \emph{auto-parallelization} to accomplish data parallelism, and unlike the other two kinds of parallelism, it modifies the dataflow graph and potentially the semantics of the program.

In our example of Figure~\ref{fig:dataflow-example}, we want to exploit data parallelism on video streams from different cameras. In the \texttt{classify} stage of the pipeline, we are classifying images from different cameras separately, so it should be able to be run in parallel.
The problem with data parallelism is that it would be cumbersome for the programmer to expose on their own; they would be forced to explicitly write dozens or hundreds of copies of the \texttt{classify} operator, and manually divide the source into dozens or hundreds of different sources, so that each operator got its own subset of the input data.
To avoid this, DSPS automatically replicate operators in the dataflow graph into several parallel copies. Typically, the number of parallel copies can be configured by the programmer by setting the level of parallelism.

\begin{figure}[t]
\centering
\begin{tikzpicture}[node distance=0.5cm,every node/.style={font=\small}]
\node[source] (in1) {input};
\node[source, below=of in1] (in2) {input};
\node[source, below=of in2] (in3) {input};
\node[operator, right=of in1] (op11) {keyBy(deviceID)};
\node[operator, right=of in2] (op12) {keyBy(deviceID)};
\node[operator, right=of in3] (op13) {keyBy(deviceID)};
\node[operator, right=of op11] (op21) {classify};
\node[operator, right=of op12] (op22) {classify};
\node[operator, right=of op13] (op23) {classify};
\node[operator, right=1.5cm of op21] (op31) {keyBy(location)};
\node[operator, right=1.5cm of op22] (op32) {keyBy(location)};
\node[operator, right=1.5cm of op23] (op33) {keyBy(location)};
\node[operator, right=of op31] (op41) {sliding window \\ (10 min)};
\node[operator, right=of op32] (op42) {sliding window \\ (10 min)};
\node[operator, right=of op33] (op43) {sliding window \\ (10 min)};
\node[sink, right=of op42] (out) {output};

\draw[dataflowedge] (in1) -- (op11);
\draw[dataflowedge] (in2) -- (op12);
\draw[dataflowedge] (in3) -- (op13);
\draw[dataflowedge] (op11) -- (op21);
\draw[dataflowedge] (op12) -- (op22);
\draw[dataflowedge] (op13) -- (op23);
\draw[dataflowedge] (op21.east) -- (op31.west);
\draw[dataflowedge] (op21.east) -- (op32.west);
\draw[dataflowedge] (op21.east) -- (op33.west);
\draw[dataflowedge] (op22.east) -- (op31.west);
\draw[dataflowedge] (op22.east) -- (op32.west);
\draw[dataflowedge] (op22.east) -- (op33.west);
\draw[dataflowedge] (op23.east) -- (op31.west);
\draw[dataflowedge] (op23.east) -- (op32.west);
\draw[dataflowedge] (op23.east) -- (op33.west);
\draw[dataflowedge] (op31) -- (op41);
\draw[dataflowedge] (op32) -- (op42);
\draw[dataflowedge] (op33) -- (op43);
\draw[dataflowedge] (op41.east) -- (out);
\draw[dataflowedge] (op42.east) -- (out);
\draw[dataflowedge] (op43.east) -- (out);
\end{tikzpicture}

\caption{Example DSP dataflow graph after operator replication.}
\label{fig:dataflow-example-parallel}
\end{figure}

On our example, a possible auto-parallelized graph produced by the system is shown in Figure~\ref{fig:dataflow-example-parallel}.
Each operator is replicated, in this case into $3$ copies.
However, this does not fully describe what happens, because we have to understand the connections between operators. If there was an edge before, now there are $9$ possible edges, and the system must decide which of them to use, and how to send data along the edges.

Typically there are several possible strategies, and the system chooses one based on context and/or explicit user configuration. One strategy is \emph{round-robin}, where outputs from one stage of the pipeline are sent to the inputs of the next stage in round-robin order (so for every $3$ outputs from one stage, $1$ gets sent to each of the $3$ operators in the following stage). A second strategy is \emph{key-based partitioning} where the operator copy that an item is sent to depends on (a hash of) a specified key. Finally, in cases where there are the same number of parallel copies from one stage to the next, it is common to \emph{preserve the same partitioning} from one stage to the next.

The partition operator \texttt{keyBy} in our example dataflow graph has no effect except to force a particular strategy for connections between stages: key-based partitioning based on the specified key.
In Figure~\ref{fig:dataflow-example-parallel}, first we assume that the input arrives partitioned by device ID. The \texttt{keyBy} by device ID then preserves such a partitioning. All future operators preserve the same partitioning, except when there is a second \texttt{keyBy} by location -- this operator re-partitions the data based on location instead of device ID.

Formally, we make no assumption about the different DSPS programming models and how they handle connections between stages, except that they should obey any constraints that are explicitly programmed by the user. We capture the allowable parallelization in an annotated DSP graph in the following definition.

\begin{definition}[Annotated Dataflow Graph and Parallelization]
\label{def:dataflow-graph-parallelized}
An \emph{annotated dataflow graph} consists of a dataflow graph annotated with, for each edge, whether the connection between parallel operator replicas should be (1) round-robin, (2) on the basis of a particular key, (3) partition-preserving, or (4) unspecified.
Additionally, each vertex may be labeled with a level of parallelism that is allowed ($1$ for no parallelism).

A \emph{parallelization} of an annotated dataflow graph consists of a larger graph, where:
(i) each vertex is replicated to between $1$ and $i$ copies, where $i$ is allowed level of parallelism; (ii) for each edge between $v$ and $v'$, if $v$ has $i$ copies and $v'$ has $i'$ copies, the connection must be consistent with the annotation. Specifically, (1) for round-robin items should be assigned to each operator in turn; (2) for key-based partitioning there should exist *some* partitioning of the keys such that that partition determines where a data item is sent next; (3) for partition-preserving, we must have $i = i'$ and the connections are one input to one output; (4) for unspecified, each output item from one stage may be sent to any of the operators for the next stage, as the system sees fit.
\end{definition}

\subsection{Streaming Runtime (Fault Tolerance and Scheduling)}

Once given a parallelized dataflow graph, the primary job of a DSPS runtime is to \emph{schedule} workers in a distributed cluster so as to execute all the operators, continuously and in parallel. The goal of the scheduler is to maximally utilize the available distributed resources, and to prevent one task from becoming a performance bottleneck (called a \emph{straggler}).
In the case of stragglers, there are common techniques for the system to respond, e.g. \emph{throttling} and \emph{back-pressure}.

The performance of the system is generally measured in terms of \emph{latency} and \emph{throughput}. Latency is the time it takes for an output item to be produced after the input item which triggered the production arrives in the system. Throughput is total number of input items successfully processed per unit time.
Throughput is often measured as \emph{max throughput}, the maximum input rate the system can handle before it breaks.
Given fixed resources, there is always some limit to how much input the system can handle; so max throughput is always finite. Beyond the max throughput, DSPS offer few guarantees about behavior, and will likely suffer linearly increasing latency, drop data, or crash altogether.

Finally, DSPS runtimes try to provide all of this with a guarantee of \emph{fault-tolerance}. Whenever a worker is assigned to process some set of items from the input stream, the worker may fail. If this occurs, the system must have a way to rewind back to a safe state and re-process those input items, or re-assign them to a new worker. It is challenging to accomplish this in a way that minimizes overhead and also minimizes the time to recovery when experiencing a fault (see~\cite{venkataraman2017drizzle}).

\section{Limitations}

% TODO: bullet point(s) on lack of commonality between different systems (as promised in the introduction)

\begin{itemize}
\item \emph{Lack of semantics.}
There exists no widely accepted common semantics for distributed stream processing.
DSPS applications are always written as dataflow graphs, and there are other common elements,
but beyond this different APIs make different choices.
For example, Flink's API
assumes that data arrives in-order per-key, whereas Timely's API does not offer this guarantee.
Specific constructs then come with other differences, for example: whether watermarks (indicating stream progress) are explicitly available or implicit;
and
whether side effects are allowed in an operator or whether the system makes no guarantees in the presence of side effects.

% TODO: fix nondeterminism vs. semantics-preserving, should be two different bullets
\item \emph{Nondeterminism.}
Unfortunately, auto-parallelization of stream processing applications
is not semantics-preserving~\cite{xiao2014nondeterminism,schneider2013safe,hirzel2014catalog}~\citeMain{pldi19},
which results in nondeterminism due to ordering of distributed events.
If nondterminism affects the output, it is usually undesirable as it can lead to bugs that are difficult to identify and reproduce.

In practice, many standard operators are not affected by such reordering: e.g.,
commutative, associative reduce operations or stateless maps and filters.
However, most DSPS do not enforce annotations to determine when it is desirable or not~\cite{schneider2013safe}.

\item \emph{Low-level state management.}
DSPS applications are built under the assumption that users should not have to
write state management logic on their own, intsead relying on predefined
dataflow operators (e.g. maps, filters, aggregation, windowing, and SQL query libraries).
In practice, however, some streaming operations require custom logic.
Examples of more complex logic include linear interpolation (fill in missing input data in a temporally dependent manner),
machine learning operators (aggregate and update a statistical model),
and event-dependent windows (form a window with data-dependent start and closing times).
Because of the ubiquity of such manual state management tasks,
popular APIs (including Storm, Flink, and Timely) allow users to program
operators manually, e.g. providing a state type, an initial state, and an
update function for each input tuple.
However, such operators are difficult to program because they must work under
the sharding mentioned above.
Additionally, if the operator requires interaction with an external service or has side effects (e.g. querying a database), state update logic has to be tolerant to unexpected behavior in case of node failures or network communication; yet in practice, users simply ignore these concerns and this results in applications that may crash unexpectedly on a failure.
As a result of these concerns, DSPS developers and researchers generally agree
that better high-level query constructs are needed that alleviate the need for low-level programming.

% TODO: heading where this is a relevant point
% In practice, these challenges are partially addressed by rigorous testing, data validation, and offloading of key functionality such as reliable storage to external services.

\item \emph{Manual parallel programming.}
Related to low-level state management, DSPS also promise a programming framework
where users should not have to parallelize their application themselves.
However, in practice, many applications are highly difficult to parallelize and require low-level constructs: for example, a \emph{broadcast} construct is used to broadcast important shared or global state to other nodes.
Such parallel programming is highly prone to correctness bugs.

\item \emph{Unpredictable performance.}
Because operators and input data are partitioned by the system, users
do not describe explicitly how to partition them.
However, DSPS do not offer any concrete guarantees about the throughput or latency of the runtime.
In particular, unexpected performance bugs arise in the
case that partitioning is not efficient.
For instance, in an example application processing
an input stream of webpage views, if most of the views come from the same website,
partitioning by key fails and results in a performance bottleneck.
To address these bugs requires that we have more reliable performance guarantees.
Ideally, application performance could be estimated statically or in conjunction with runtime profiling.
\end{itemize}
