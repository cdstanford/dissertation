\begin{abstract}
The sheer scale of today's data processing needs has led to a new paradigm of software systems centered around requirements for high-throughput, distributed, low-latency computation.
Despite their widespread adoption, existing solutions have yet to provide a programming model with safe semantics -- and disagree on basic design choices, in particular with their approach to parallelism. As a result, \naive{} programmers are easily lead to make correctness and performance bugs.

This thesis proposes a reliable programming model for modern distributed stream processing -- including a language and type system, a semantics based on partially ordered sets, primitives for parallelism and distribution, testing techniques, and primitives for custom sequential processing. A key idea throughout our work is to \emph{model data streams as partially ordered structures}; our thesis is that this conveniently exposes parallelism without compromising safety. The ideas contained in this work are implemented in a series of open source software projects, including the DiffStream, Flumina, and Data Transducers libraries, and can be integrated with existing platforms.
\end{abstract}
