\chapter{Performance Bounds}
\label{cha:monitoring}

\headerblock{
  \headerquote{It is well known that even for simple calculations it is impossible to give an \emph{a priori} upper bound on the amount of tape a Turing machine will need for any given computation. It is precisely this feature that renders Turing's concept unrealistic.}{Rabin and Scott in ``Finite Automata and Their Decision Problems,'' 1959~\cite{rabin1959finite}}
}

In this section we describe data transducers,
an intermediate representation for modeling
stream processing operators as finite state transducers
over data words~\citeMain{icalp17,popl19,tcs20}.
Data transducers support succinct constructions, making them
compositional.
We also describe the QRE-Past monitoring language, which
can be used for monitoring stream processing applications.

The key takeaways of this section are related to performance: data transducers
as an IR allow \emph{formal guarantees} on performance.
The key theorems are \Cref{dt:thm:dt-eval}, which states streaming evaluation of a data transducer takes linear space and time (independent of the input stream size); and \Cref{dt:thm:dt-eval} which shows that a QRE-Past query can be compiled to a data transducer of quadratic size.
Putting these two results together we get formal bounds on performance for QRE-Past queries.

Unlike the rest of the thesis, this section does not consider distribution.
Providing performance upper bounds is difficult even in the sequential case, so it is a reasonable starting point.
Because it is sequential, the model is also deterministic.

\Cref{dt:sec:model} introduces the model of data transducers with illustrative examples.
In \Cref{dt:sec:constructions} we consider a number of semantic operations with
corresponding succinct constructions on DTs, and we define and study the key property of restartability
necessary for some of them.
In \Cref{dt:sec:rm}, we define the query language QRE-Past, and show how constructions on DTs
immediately yield modular compilation into a streaming evaluation algorithm.
We also show how QRE-Past is useful in specifying a cardiac arrhythmia
detection algorithm. % in a succinct and high-level manner.
\Cref{dt:sec:succinctness} discusses the expressiveness and succinctness of DTs compared to cost register automata, to finite automata, and to general streaming computations.
We conclude in \Cref{dt:sec:discussion}.

\section{Motivation}

Applications ranging from network traffic engineering to runtime monitoring of autonomous control systems
require computation over data streams in an efficient and incremental manner.
Declarative programming is a particularly appealing approach to specify the desired logic in such
applications as it can provide natural and high-level constructs for processing streaming data
with guaranteed bounds on computational resources used by the compiled implementation.
This has motivated the development of a number of declarative query languages.
For example, in runtime verification, a monitor observes a sequence of events produced by
a system, and issues an alert when a violation of a safety property is detected, where the safety property
is described in a temporal logic with past-time operators such as \emph{always-in-the-past} and \emph{since}
~\cite{manna2012temporal,havelund2004efficient}.
In quantitative monitoring, a monitor associates a numerical value with an input stream of data values,
where the desired computation is described using \emph{quantitative regular expressions} (QREs) that combine
regular patterns with numerical aggregation operations such as min, max, sum, and average~\cite{QRE,StreamQRE,YLMMAL2017NQRE}.
In each such case, the declarative specification is automatically compiled into a monitor that
adheres to the streaming model of computation~\cite{M2005DS}: memory and per-item
processing time is polynomial in the size of the specification of the query and, roughly speaking,
does not grow with the length of the input stream.

In existing query languages over streaming data, while a programmer can specify the desired computation
in a modular fashion using constructs of the query language, the compiler generates monolithic code for
a given query.
What is lacking though is an intermediate representation for streaming computations
that supports composition operations with succinct constructions so that high-level queries can be
compiled modularly. The motivation for such a model is two-fold. From a practical viewpoint,
it can facilitate the design of new query languages. For instance, suppose a user wants
to specify a monitoring property using past-time temporal logic, where the atomic
predicates involve comparing quantitative summaries defined using QREs.
Such a specification contains combinators from two different languages (QREs and past-temporal logic), and we could try to design a compiler from scratch for streaming evaluation of the more expressive, integrated language.
However, if we have a \emph{modular} compilation algorithm for the combinators of the two component languages, we get a compiler for the integrated language for free.
From a theoretical viewpoint, designing such a representation is a technical challenge since
it needs to support both combining values from parallel threads of computation (i.e. parallel composition) and unambiguous regular parsing.
In particular, although QREs can be compiled into quantitative automata known
as \emph{cost register automata}~\cite{AdADRY2013CRA}, since this compilation has provably exponential lower bound,
it is not employed by current QRE evaluation algorithms, and in fact, no existing formalism can support
modular compilation of QREs.

\section{Contributions}

The main contribution of this paper is the model of \emph{Data Transducers} (DT) as this desired
modular intermediate representation for streaming computations.
A data transducer processes a data stream---a sequence of tagged data values---and produces
a numerical (or Boolean) value using a fixed set of data variables that are updated
using a constant number of operations as it processes each tagged data value.
A DT can be viewed as a quantitative generalization of (unambiguous) NFAs.
Whereas an NFA configuration consists of a finite set of states, each of which is either inactive or active, % wording change
a DT configuration consists of a finite set of data variables, each of which can be inactive (\emph{undefined}), active
with a value (\emph{defined}), or in a special ``conflict'' mode (\emph{conflicted}).
A DT configuration thus consists of succinctly represented finite control integrated with data values.
As a DT computes by consuming tagged data values, it updates its variables using a specified allowed
set of operations. The values of defined variables can be combined using operations to form new values,
but there is also the possibility of a ``collision''.
This is analogous to how two tokens of active NFA states can be merged into one token
during evaluation when they are placed on the same state. Since the merging of data values
is not in general a meaningful operation, a collision of values results in a variable being set
to conflict.
Since multiple transitions can write to the same data variable while processing a single tagged data value,
and the updated value of a variable can depend on the updated values of the others,
the semantics is defined using fixed points.
We show how this semantics can be implemented
by an efficient streaming algorithm for evaluation that executes a linear (in the size of DT) number
of data operations while processing each tagged data value.

The language of a DT, i.e. the set of stream histories for which its output is defined,
is a regular language over the tags of the input stream.
In fact, DTs capture a robust class of functions with an elegant logical
characterization: MSO-definable string-to-DAG % condensed to save space
transformations with a special ``no backward edges'' requirement. % added...not sure
This class, which we call \emph{streamable regular transductions}, has been studied in
\cite{EM1999MTT,C1994MSOGT} \citeMain{tcs20}, and the closure properties of this class, as opposed to some specific constructs supported by
query languages in the existing literature, guide the choice of operations over
DTs for which we seek succinct constructions. % replaced (hopefully succinct) -> succinct

In particular, we show that DTs are closed under
quantitative concatenation, quantitative iteration, union, and parallel composition operations,
and that the corresponding constructions are succinct.
We also consider the \emph{prefix-sum} operation that combines the outputs on all prefixes using
a specified aggregator; this also has a simple and succinct construction on DTs.
Temporal operators such as ``always in the past'', ``sometime in the past'', and ``since'' can be
implemented using prefix-sum.
The design choices in the precise formal definition of the model turn out to be critical in these constructions.
A key restriction on DTs, which we call \emph{restartability}, that is required
for constructions related to unambiguous parsing is identified.
This restriction says that it is possible to ``restart'' the automaton during
a computation by placing new data values at its initial states.
Then, although we only need to store a single automaton configuration in memory, the output is the same as if multiple copies of the automaton were computing
independently on multiple stream suffixes as long as only one of these copies ultimately contributes to the final output.
This ability is necessary for efficient unambiguous parsing: several parsing possibilities
are explored simultaneously, but the required space is constant.

To illustrate the benefits of modular compilation, we define a new query language, called QRE-Past,
that combines the features of past-time temporal logic and QREs.
We specify a cardiac arrhythmia detection algorithm~\cite{AAMMR2018,ZI2016ICD} in QRE-Past to illustrate how
the combination of features leads to a natural high-level specification.
The theory of DTs immediately leads to a streaming evaluation algorithm for QRE-Past,
since every construct in QRE-Past maps to a corresponding construction on component DTs without
causing blow-up.
In fact, there is nothing sacred about QRE-Past: the designer of a high-level
query language over streaming data for a specific domain can introduce new combinators,
in addition to the ones in this paper, as long as there are corresponding succinct constructions
on the low-level model of DTs.

Finally, while there are existing models
with identical expressiveness, DTs are exponentially more succinct (for instance, compared
to unambiguous cost register automata). To gain a better understanding of the
expressiveness and succinctness of DTs,
consider a (generic) streaming algorithm that maintains a fixed number of Boolean and data
variables, and processes each tagged data value by updating these variables by executing a loop-free
code. While such algorithms capture \emph{all} streaming computations, the class of all streaming
computations is not suitable for modular specifications.
For instance, consider the quantitative concatenation operation:
given transductions $f$ and $g$, and a binary data operation ${\textit{op}}$,
$h={\textit{split}}(f,g,{\textit{op}})$ splits the inputs stream $w$ uniquely into two parts $w=w_1w_2$ and
returns $h(w)={\textit{op}}(f(w_1),g(w_2))$.
While DTs are closed under this operation, the class
of all streaming algorithms is not.
We can enforce regularity of a generic streaming algorithm by requiring, for instance, that the updates to the Boolean
variables are not influenced by the values of the data variables. We show that streaming algorithms
with these restrictions can be translated to DTs without any blow-up, thus establishing that
DTs are the most succinct (up to a constant factor) representation of streamable regular transductions.
The structure of a DT---as variables ranging over undefined/defined/conflict values and update code as a set
of transitions of a particular form, as opposed to traditional loop-free update code---not only enforces regularity, but is also what allows us to define succinct constructions
on the representation.

\section{Data Transducers}
\label{dt:sec:model}
\label{dt:subsec:preliminaries}

\subsection{Preliminaries}

To model data streams we use \emph{data words}.
Let $\data$ be a (possibly infinite) set of \emph{data values},
such as the set of integers or real numbers,
and let $\Sigma$ be a finite set of \emph{tags}.
Then a \emph{data word} is a sequence of tagged data values
$\trc{w} \in (\Sigma \times \data)^*$.
We write $\trc{w} \downarrow \Sigma$ to denote
the projection of $\trc{w}$ to a string in $\Sigma^*$.
We use bold $\trc{u}$, $\trc{v}$, $\trc{w}$ to denote data words.
We reserve non-bold $u, v, w$ for plain strings of tags in $\Sigma^*$.
We write $d, d_i$ for elements of $\data$.
We use $\sigma$ to denote an arbitrary tag in $\Sigma$,
and in the examples we write particular tags in typewriter font, e.g. $\tg{a}, \tg{b}$.

A \emph{signature} is a tuple $(\data, \ops)$,
where $\data$ is a set of data values
and $\ops$ is a set of \emph{allowed operations}.
Each operation has an \emph{arity} $k \ge 0$
and is a function from $\data^k$ to $\data$.
We use $\ops_k$ to denote the $k$-ary operations.
For instance, if $\data$ is all 64-bit integers, we might support 64-bit arithmetic, as well as
integer division and equality tests.
Alternatively we might have $\data = \mathbb{N}$
with the operations $+$ (arity 2), $\min$ (arity 2), and $0$ (arity 0).
In general, we may have arbitrary user-defined operations on $\data$.
Given a signature $(\data, \ops)$,
and a collection of variables $Z$,
the set of \emph{terms} $\tms[Z]$
consists of all syntactically correct expressions
with free variables in $Z$, using operations $\ops$.
So $\min(x,0) + \min(y,0)$ and $x + x$
are terms over the signature $(\mathbb{N}, \{+,\min,0\})$ with $Z = \{x,y\}$.

We define two special values in addition to
the values in $\data$: $\bot$ denotes \emph{undefined}
and $\top$ denotes \emph{conflict}.
We let $\cdata := \data \cup \{\bot, \top\}$ be the set of \emph{extended data values},
and refer to elements of $\data$ as \emph{defined}.
We lift $\ops$ to operations on $\cdata$ by thinking of $\bot$ as the empty multiset,
elements of $\data$ as singleton multisets, and $\top$ as any multiset of two or more data values.
The specific behavior of $\op \in \ops$ on values in $\cdata$
is illustrated in the table below
for the case $\op \in \ops{}_2$.
We also define a \emph{union} operation $\sqcup: \cdata \times \cdata \to \cdata$:
if either of its arguments is undefined it returns the other one,
and in all other cases it returns conflict.
This represents multiset union. Note that $d_1 \sqcup d_2 = \top$ even if $d_1 = d_2$.
This is essential: it guarantees that for all operations on extended data values, whether the result is undefined, defined, or conflict can be determined from knowing only whether the inputs are undefined, defined, or conflict.
For instance, we rely on this guarantee for the theorems in
\Cref{dt:subsec:dt-regularity} and for the translation from QRE-Past in \Cref{dt:subsec:rm-compilation}. It's not needed for most of the constructions in \Cref{dt:sec:constructions}.
\[
\begin{array}{c|ccc}
\sqcup & \bot & d_2 & \top \\
\hline
\bot & \bot & d_2 & \top \\
d_1 & d_1 & \top & \top \\
\top & \top & \top & \top
\end{array}
\qquad \qquad
\begin{array}{c|ccc}
\op & \bot & d_2 & \top \\
\hline
\bot & \bot & \bot & \bot \\
d_1 & \bot & \hspace{-5pt}\op(d_1,d_2)\hspace{-5pt} & \top \\
\top & \bot & \top & \top
\end{array}
\]

$\cdata$ is a \emph{complete lattice}, partially ordered under the
relation $\le$ which is defined by $\bot \le d \le \top$ for all $d \in \data$,
and distinct elements $d, d' \in \data$ are incomparable.
For a finite set $X$, we write the set of functions $X \to \cdata$ as $\cdata^X$; its elements are untagged \emph{data vectors}, denoted $\trc{x}$, $\trc{y}$.
The partial order extends coordinate-wise to an ordering $\trc{x} \le \trc{y}$ on data vectors $\trc{x}, \trc{y} \in \cdata^X$.
All operations in $\ops{}$ are \emph{monotone increasing}
w.r.t. this partial order.
Union ($\sqcup$) is commutative and associative, with identity $\bot$ and absorbing element $\top$,
and \emph{all} $k$-ary operations distribute over it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Syntax}
Let $(\data, \ops)$ be a fixed signature.
A \emph{data transducer (DT)} is a 5-tuple
\[
\DT = \DTtuple,
\]
where:
\begin{itemize}
\item $\states$ is a finite set of \emph{state variables} (\emph{states} for short) and $\tags$ is a finite set of \emph{tags}.
We write $\states'$ for a copy of the variables in $\states$: for $q \in \states$, $q' \in \states'$ denotes the copy. When the states of the DT are updated, $q'$ will be the new, updated value of $q$.
\item $\update$ is a finite set of \emph{transitions},
where each transition is a tuple $(\sigma, X, q', t)$.
\begin{itemize}
\item $\sigma \in \Sigma \cup \{\tg{i}\}$,
where $\tg{i} \notin \Sigma$, and if $\sigma = \tg{i}$ this is a special \emph{initial transition}.
\item $X \subseteq \states \cup \states'$ is a set of
\emph{source variables} and $q' \in \states'$ is the \emph{target variable}.
\item $t \in \tms[X \cup \{\curritem\}]$ gives a new value of the target variable given values of the source variables
and given the value of ``$\curritem$'', which represents the current data value in the input data word.
Assume that $\curritem \notin X$.
We allow $X$ to include some variables not used in $t$.
For initial transitions, we additionally require that $X \subseteq \states'$ and that $\curritem$ does not appear in $t$.
\end{itemize}
\item $\init \subseteq \states$ is a set of \emph{initial states} and $\final \subseteq \states$ is a set of \emph{final states}.
\end{itemize}

The \emph{number of states} of $\DT$ is $|\states|$.
The \emph{size} of $\DT$ is the the number of states plus the total length of all transitions
$(\sigma, X, q', t)$, which includes the length of description of all the terms $t$.

\subsection{Semantics}
\label{dt:subsec:dt-semantics}

The input to a DT has two components.
First, an \emph{initial vector} $\trc{x} \in \cdata^\init$, which assigns an extended data value to each initial state. Second, an \emph{input data word} $\trc{w} \in (\Sigma \times D)^*$, which is a sequence of tagged data values to be processed by the transducer. On input $(\trc{x},\trc{w})$, the DT's final \emph{output vector} is an extended data value at each of its final states.
Thus, the semantics of $\DT$ will be
\[
\sem{\DT} : \cdata^\init \times (\tags \times \data)^* \to \cdata^\final.
\]

A \emph{configuration} is a vector $\trc{c} \in \cdata^\states$.
For every $\sigma \in \Sigma$, the set of transitions $(\sigma, X, q', t)$
collectively define a function $\update_\sigma : \cdata^\states \times \data \to \cdata^\states$:
given the current configuration and the current data value from the input data word,
$\update_\sigma$ produces the next configuration.
We define $\update_\sigma(\trc{c},d)(q) := \trc{c}'(q')$,
where $\trc{c}' \in \cdata^{Q \cup Q' \cup \{\curritem\}}$ is the \emph{least vector} satisfying
$\trc{c}'(\curritem) = d$; for all $q \in Q$, $\trc{c}'(q) = \trc{c}(q)$;
and
\begin{equation}
\text{for all }q' \in Q',\quad
\trc{c}'(q') = \bigsqcup_{(\sigma, X, q', t) \in \update} \sem{t}(\trc{c}'|_X),
\label{dt:eq:fixpoint-semantics}
\end{equation}
where we define $\sem{t}(\trc{c}'|_X)$ to be $\bot$ if there exists $x \in X$ such that $\trc{c}'(x) = \bot$; otherwise, $\top$ if there exists $x \in X$ such that $\trc{c}'(x) = \top$; otherwise, if all variables in $X$ are defined, then $\sem{t}(\trc{c}'|_X)$ is the value of the expression $t$ with variables assigned the values in $\trc{c}'$.
So, $\sem{t}(\trc{c}'|_X)$ produces $\bot$ or $\top$ if some variable in $X$ is $\bot$ or $\top$.
The above union is over all transitions with label $\sigma$ and target variable $q'$.
Since $\cdata$ is a complete lattice, this least fixed point exists by the Knaster-Tarski theorem.

The case of initial transitions ($\update_\tg{i}$) is slightly different. The purpose of initial transitions is to compute an initial configuration $\trc{c}_0 \in \cdata^{\states}$, given the initial vector $\trc{x} \in \cdata^\init$. There is no previous configuration, and no current data value, which is why we required $X \subseteq \states'$ for initial transitions and $\curritem$ was not allowed.
We define the function $\update_\tg{i}: \cdata^\init \to \cdata^\states$ with the same fixed point computation from Equation~\eqref{dt:eq:fixpoint-semantics}, except that the initial states are additionally assigned values given by the vector $\trc{x}$. Define that $\trc{x}(q) = \bot$ if $q \notin \init$. Then define $\update_\tg{i}(\trc{x}) = \trc{c}'$, where $\trc{c}'$ is the \emph{least vector} satisfying, for all $q \in Q$,
$\trc{c}'(q') = \trc{x}(q) \sqcup \bigsqcup_{(\tg{i}, X, q', t) \in \update} \sem{t}(\trc{c}'|_X).$

Now $\DT$ is evaluated on input
$(\trc{x}, \trc{w}) \in \cdata^\init \times (\Sigma \times \data)^*$
by starting from the initial configuration and applying the update functions in sequence as illustrated in
Figure~\ref{dt:fig:dt-eval-illustration}.
Finally, the output $\trc{y} \in \cdata^\final$ is given by $\trc{y} = \trc{c}|_{\final}$, the projection of $\trc{c}$ to the final states.

\begin{figure}[t]
\centering \small
\tikzset{>=stealth',auto,semithick,
        node distance=0.8cm,
        square/.style={draw,inner sep=0pt,fill=white,
        regular polygon,regular polygon sides=4,minimum size=25pt}}
%% Background layer
\pgfdeclarelayer{bg}
\pgfsetlayers{bg,main}
\begin{tikzpicture}[scale=0.8]
%%%
\node (x1) at (-1.5,0.2) {$x_1$};
\node (x2) at (-1.5,-0.2) {$x_2$};
\node (y) at (10,0) {$y$};
\node[square] (i) at (0,0) {$\update_\tg{i}$};
\node[square] (1) at (2,0) {$\update_\tg{a}$};
  \node[draw=none] (d1) at (2,1.1) {$d_1$};
\node[square] (2) at (4,0) {$\update_\tg{b}$};
  \node[draw=none] (d2) at (4,1.1) {$d_2$};
\node[square] (3) at (6,0) {$\update_\tg{a}$};
  \node[draw=none] (d3) at (6,1.1) {$d_3$};
\node[square] (4) at (8,0) {$\update_\tg{a}$};
  \node[draw=none] (d4) at (8,1.1) {$d_4$};
% Edges
\draw[->] (x1) -- (i);
\draw[->] (x2) -- (i);
\draw[->] (4) edge node {$\trc{c}_4$} (y);
%%%
\draw[->] (d1) -- (1);
\draw[->] (d2) -- (2);
\draw[->] (d3) -- (3);
\draw[->] (d4) -- (4);
%%
\draw[->] (i) edge node {$\trc{c}_0$} (1);
\draw[->] (1) edge node {$\trc{c}_1$} (2);
\draw[->] (2) edge node {$\trc{c}_2$} (3);
\draw[->] (3) edge node {$\trc{c}_3$} (4);
\end{tikzpicture}
\caption[Data transducer semantics illustration.]{Example evaluation of a data transducer $\DT$ with two initial states and one final state on initial vector $(\trc{x}_1, \trc{x}_2)$ and an input data word $\trc{w}$ consisting of four characters (tagged data values):
$(\tg{a},d_1)$, $(\tg{b},d_2)$, $(\tg{a},d_3)$, $(\tg{a}, d_4)$, to produce output $y$.
Here $\trc{c}_0, \trc{c}_1, \trc{c}_2, \trc{c}_3$, and $\trc{c}_4$ are configurations; $d_i \in \data$; and $x_1, x_2, y \in \cdata$. Each $\Delta_\sigma$ is a set of transitions, collectively describing the next configuration in terms of the previous one.}
\label{dt:fig:dt-eval-illustration}
\end{figure}

\subsection{Streaming Evaluation Algorithm}
Evaluation complexity of a data transducer depends on the underlying
operations, so we give a conditional result where the complexity
is stated in terms of the number of data registers and number of
operations on those data registers.

\begin{theorem}
Evaluation of a data transducer $\DT$, with number of states $n$ and size $m$ on input $(\trc{x},\trc{w})$, requires
$O(n)$ data registers to store the state,
and $O(m)$ operations and additional data registers
to process each element in $\tags \times \data$, independent of $\trc{w}$.
The evaluation algorithm is given in Figure~\ref{dt:fig:dt-eval-algorithm}.
\label{dt:thm:dt-eval}
\end{theorem}

\begin{figure}[t]
\vspace{-8pt}
\centering \footnotesize
\begin{algorithmic}

\State $\trc{c} \gets \update_{\tg{i}}(\trc{x})$; produce output $\trc{y} = \trc{c}|_{\final}$

\For{each character $(\sigma,d)$ in $\trc{w}$}
    \For{each state $q \in Q$}
        $\mathit{val}(q) \gets \trc{c}(q)$;
        $\mathit{val}(q') \gets \bot$
    \EndFor
    \For{each transition $\tau \in \update_\sigma$}
        $\mathit{val}(\tau) \gets \bot$;
        $\mathit{num\_undef}(\tau) \gets |X|$
    \EndFor
    \State $\mathit{worklist} \gets Q' \cup \update_\sigma$
    \While{$\mathit{worklist}$ is nonempty, \textbf{get} $\mathit{item}$ from $\mathit{worklist}$ and}
        % \State $\mathit{item} \gets \mathit{worklist}.\texttt{pop()}$
        \If{$\mathit{item}$ is a transition $\tau = (\sigma, X, q', t) \in \update_\sigma$:}
            \State $\mathit{val}(\tau) \gets \sem{t}(\mathit{val}|_X)$
            \If{$\mathit{val}(q') \ne \top$}
                add $q'$ to $\mathit{worklist}$
            \EndIf
        \ElsIf{$\mathit{item}$ is a state $q' \in Q'$}
            \If{$\mathit{val}(q') = \bot$}
                \For{each $\tau \in \update_\sigma$ with source variable $q'$}
                    $\mathit{num\_undef}(\tau) \gets \mathit{num\_undef}(\tau) - 1$
                \EndFor
            \EndIf
            \State $\mathit{val}(q') \gets \bigsqcup_{\tau = (\sigma, X, q', t)} \mathit{val}(\tau)$
            \For{each $\tau \in \update_\sigma$ with target variable $q'$}
                \If{$\mathit{val}(\tau) \in \data$ or ($\mathit{val}(\tau) = \bot$ and $\mathit{num\_undef}(\tau) = 0$)}
                    add $\tau$ to $\mathit{worklist}$
                \EndIf
            \EndFor
        \EndIf
    \EndWhile
    %% Compactified a bit
    % \State $\trc{c} \gets \mathit{val}|_{Q'}$; produce output $\trc{y} = \trc{c}|_{\final}$
    \For{each $q \in Q$}
        $\trc{c}(q) \gets \mathit{val}(q')$
    \EndFor
    \State produce output $\trc{y} = \trc{c}|_{\final}$
\EndFor
\end{algorithmic}
\caption[Data transducer evaluation algorithm.]{Data transducer evaluation algorithm (Theorem~\ref{dt:thm:dt-eval}). On input $\DT = \DTtuple$ over $(\data, \ops)$, an initial vector $\trc{x} \in \cdata^\init$, and a data stream $\trc{w} \in (\Sigma \times \data)^*$, produces the output vector $\trc{y} \in \cdata^\final$ on each prefix of $\trc{w}$.
}
\label{dt:fig:dt-eval-algorithm}
\end{figure}

\subsection{Regularity}
\label{dt:subsec:dt-regularity}
Data transducers define \emph{regular transductions} on data words (see \Cref{dt:subsec:dts-and-cras}). Here, we show regularity in a simpler sense: whether an output value is defined (or undefined, or conflict) depends only on whether the input values are undefined, defined, or conflict, together with some regular property of the string of tags. For data vectors $\trc{x}_1, \trc{x}_2 \in {\cdata}^X$, we say that $\trc{x}_1$ and $\trc{x}_2$ are \emph{equivalent}, and write $\trc{x}_1 \equiv \trc{x}_2$, if for all $x \in X$, $\trc{x}_1(x)$ and $\trc{x}_2(x)$ are both undefined, both defined, or both conflict.

\begin{theorem}
\label{dt:thm:regular-language}
Let $\DT = \DTtuple$ be a DT over $(\data, \ops)$. Then:
(i) For all initial vectors $\trc{x}_1, \trc{x}_2 \in \data^\init$,
and for all input words $\trc{w}_1, \trc{w}_2$,
if $\trc{x}_1 \equiv \trc{x}_2$ and $\trc{w}_1 \downarrow \Sigma = \trc{w}_2 \downarrow \Sigma$,
then $\sem{\DT}(\trc{x}_1,\trc{w}_1) \equiv \sem{\DT}(\trc{x}_2,\trc{w}_2)$.
(ii) For every equivalence class of initial vectors $\trc{x}$ and equivalence class of output vectors $\trc{y}$, the set of strings $\trc{w} \downarrow \Sigma$ such that $\sem{\DT}(\trc{x},\trc{w}) \equiv \trc{y}$ is regular.
\end{theorem}
\begin{proof}
In evaluating a DT we may collapse all values in $\data$ to a single
value $\one$, so each state takes values in $\{\bot, \one, \top\}$.
This gives a projection from $\DT$ to a DT
$\aut{P}$ over the \emph{unit signature} $(\UU, \Uops)$,
where $\UU = \{\one\}$ is a set with just one element,
and $\Uops$ consists of, for each $k$, the unique
map $\uop_k : \UU^k \to \UU$.
The projection homomorphically preserves the semantics.
Then, (i) follows because the computation of $\aut{P}$ is exactly the same
on $\trc{x}_1, \trc{w}_1$ and $\trc{x}_2, \trc{w}_2$, and (ii) follows because $\aut{P}$ has finitely many possible configurations.
\end{proof}

We can thus define the \emph{language} of $\DT$ to be $\lang(\DT) = \{\trc{w} \downarrow \Sigma \mid \sem{\DT}(\trc{x},\trc{w}) \in \data^\final \text{ for some } \trc{x} \in \data^\init\}$, so $\lang(\DT) \subseteq \Sigma^*$. This is the set of tag strings $\trc{w} \downarrow \Sigma$ such that, if the initial vector of values is all defined, after reading in $\trc{w}$ all final states are defined.
We similarly define the set of strings on which a DT is \emph{defined or conflict}, on input of the same form: the \emph{extended language} $\clang(\DT)$ is
$\{\trc{w} \downarrow \Sigma \mid \sem{\DT}(\trc{x},\trc{w}) \in (\data \cup \{\top\})^\final \text{ for some } \trc{x} \in (\data \cup \{\top\})^\init\}$.
An immediate corollary of Theorem~\ref{dt:thm:regular-language} is that
(i) $\lang(\DT)$ is regular, (ii) $\clang(\DT)$ is regular, and (iii) $\lang(\DT) \subseteq \clang(\DT)$.
Finally, say that DTs $\DT_1$ and $\DT_2$ are \emph{equivalent} if for all $\trc{x}_1 \equiv \trc{x}_2$ and
for all $\trc{w}$, $\sem{\DT_1}(\trc{x}_1,\trc{w}) \equiv \sem{\DT_2}(\trc{x}_2,\trc{w})$.

\begin{theorem}
\label{dt:thm:equivalence-pspace-complete}
On input DTs $\DT_1$, $\DT_2$,
deciding if $\DT_1$ and $\DT_2$ are equivalent is PSPACE-complete.
\end{theorem}
\begin{proof}
We first decide if the two are \emph{not} equivalent in NPSPACE.
It suffices to project $\DT_1$ and $\DT_2$ to DTs
over the unit signature, $\aut{P}_1$ and $\aut{P}_2$, as in the previous proof,
and decide if $\aut{P}_1 \not\equiv \aut{P}_2$.
Let $n$ be the number of states between $\aut{P}_1$ and $\aut{P}_2$,
and let $m$ be their combined size.
The number of configurations for $\aut{P}_1$ and $\aut{P}_2$ together is $3^n$.
Therefore, if there is a counterexample, it is some string over $\Sigma$ of length at most $3^n$.
Guessing the counterexample one character at a time
requires linear in $n$ space to record the count and $O(m)$ space to update
$\aut{P}_1$ and $\aut{P}_2$ (by Theorem~\ref{dt:thm:dt-eval}).

To show it is PSPACE-hard,
it suffices to exhibit a translation from NFAs to
DTs which reduces
language equality of NFAs to equivalence of DTs.
Specifically, we create $\DT$ with one final state
which is undefined on strings for which the NFA is undefined, and $\top$
on strings for which the NFA is defined.
The translation works by directly copying the states and transitions of the NFA, except we add \emph{two} additional transitions from accepting states of the NFA to the new final state of $\DT$.
\end{proof}

\section{Examples}
\label{subsec:dt-examples}

We do not envision that DTs would be directly programmed by users, due to the conceptual difficulty of tracking undefined, defined, and conflicted values. Rather, DTs would be a low-level, back-end model for streaming and monitoring.
The purpose of this section is mainly to illustrate, informally and through examples, the basic features and execution semantics of the model.

We present only \emph{acyclic} DTs in this section, and we take $I = \varnothing$: all initialization is done with initial transitions $\update_{\tg{i}}$. Additionally, we use the abbreviation $q' := t$ to denote a transition $(\sigma, X, q', t)$, where $X$ is exactly the set of variables present in the term $t$ (in contexts where $\sigma$ is clear). In general, $X$ may include other variables unused in $t$, and the semantics of the transition does depend on the unused variables as well (see \S\ref{dt:subsec:dt-semantics}, ``Why do variables in $X$ unused in $t$ affect the semantics?'').

\paragraph*{Pattern matching.}
DTs are based on the idea of merging \emph{data registers} and \emph{finite control} into the single set of ``state variables'' $Q$.
Suppose we wish to monitor a stream of $\tg{a}$-events, $\tg{b}$-events, and $\tg{\#}$-events, where each $\tg{a}$- or $\tg{b}$-event is the price at which an item was bought, and $\tg{\#}$ indicates the end of a day. We thus have $\data = \mathbb{Q}$ and $\tags = \{\tg{a}, \tg{b}, \tg{\#}\}$. For the operations $\ops$, we allow $+, -, \cdot, \max, \min$, division $/$ (this must return a default value on division by $0$), and integer constants.
Suppose we want to output the average price of a \emph{sliding window} containing the last three $\tg{a}$ prices, which resets at the end of the day.
This is essentially a \emph{pattern match} over the input tags to locate the last three, which are then averaged. $\DT_1$ in Figure~\ref{fig:dt-example-sliding} is based on this idea.
The transitions listed under $\textsf{transitions}(\sigma)$ are those labeled with $\sigma$;
we use $\parallel{}$ to emphasize that the transitions are not ordered.

The machine $\DT_1$ uses state variables \texttt{sum1}, \texttt{sum2}, and \texttt{sum3} to keep track of the sum of the last 1, 2, and 3 $\tg{a}$ prices (in the current day). Each variable matches a certain pattern of tags in the input stream, namely, strings with at least 1, 2, and 3 $\tg{a}$'s so far.
In addition to pattern-matching, the variables are updated to keep track of the sum.
For example, the transition $\texttt{sum2}' := \texttt{sum1} + \curritem$ indicates that \emph{if} $\texttt{sum1}$ was defined before then $\texttt{sum2}$ should now be defined and equal to the sum plus the current data value. The transition $\texttt{avg}' := \texttt{sum3}'\,/\,3$ indicates that \emph{if} $\texttt{sum3}$ is \emph{now} defined (note the $\texttt{sum3}'$), then \texttt{avg} should be set to the average of the last three prices.

\begin{figure}[t]
\centering \footnotesize
\fbox{\begin{minipage}{.45\textwidth}
\vspace{-2ex}
\begin{align*}
Q = \{\texttt{sum1}, \texttt{sum2}, &\texttt{sum3}, \texttt{avg}\}, \; I = \varnothing, \; F = \{\texttt{avg}\} \\
\textsf{transitions}({\tg{i}}) \;=\; &\varnothing \\
\textsf{transitions}(\tg{a}) \;=\;
    &\parallel{} \texttt{sum1}' := \curritem \\
    &\parallel{} \texttt{sum2}' := \texttt{sum1} + \curritem \\
    &\parallel{} \texttt{sum3}' := \texttt{sum2} + \curritem \\
    &\parallel{} \texttt{avg}' := \texttt{sum3}'\,/\,3 \\
\textsf{transitions}(\tg{b}) \;=\;
    &\parallel{} \texttt{sum1}' := \texttt{sum1} \\
    &\parallel{} \texttt{sum2}' := \texttt{sum2} \\
    &\parallel{} \texttt{sum3}' := \texttt{sum3} \\
\textsf{transitions}(\tg{\#}) \;=\; &\varnothing
\end{align*}
\end{minipage}}
\fbox{\begin{minipage}{.50\textwidth}
Example evaluation on input
\[
\trc{w} = (\tg{a}, 6)(\tg{a}, 5)(\tg{a}, 7)(\tg{b}, 2)(\tg{a}, 8)(\tg{\#}, 0)(\tg{b}, 2)(\tg{a}, 7).
\]
\[
\renewcommand{\arraystretch}{1.02}
\begin{array}{c|cccc}
    \trc{w} \text{ (input)}
        & \texttt{sum1}
        & \texttt{sum2}
        & \texttt{sum3}
        & \texttt{avg} \text{ (output)} \\
    \hline
    & \bot & \bot & \bot & \bot \\
    (\tg{a}, 6) & 6 & \bot & \bot & \bot \\
    (\tg{a}, 5) & 5 & 11 & \bot & \bot \\
    (\tg{a}, 7) & 7 & 12 & 18 & 6.000 \\
    (\tg{b}, 2) & 7 & 12 & 18 & \bot \\
    (\tg{a}, 8) & 8 & 15 & 20 & 6.667 \\
    (\tg{\#}, 0) & \bot & \bot & \bot & \bot \\
    (\tg{b}, 2) & \bot & \bot & \bot & \bot \\
    (\tg{a}, 7) & 7 & \bot & \bot & \bot \\
\end{array}
\]
\end{minipage}}

\caption[Data transducer example 1.]{Data transducer $\DT_1$ monitoring a stream of purchase events for two types of items, tagged $\tg{a}$ and $\tg{b}$, and $\tg{\#}$ to represent the end of each day. Throughout the day we output the average price in a sliding window of the last three $\tg{a}$-items. The language of strings on which $\DT_1$ produces output is $(\tg{a} \cup \tg{b} \cup \tg{\#})^{*} \tg{a} \tg{b}^{*} \tg{a} \tg{b}^{*} \tg{a}$.
}
\label{fig:dt-example-sliding}
\end{figure}

\paragraph*{Multiple transitions with a single target.}
The machine $\DT_1$ has a simplifying syntactic property that for every $\sigma \in \Sigma$ and for every state $q'$, there is only one transition $q' := t$. In other words, there is only one \emph{rule} stating how to assign $q'$ a value. In general, there may be multiple rules, and the resulting value of $q'$ will be the union ($\sqcup$) over all transitions.
For instance, suppose we have the same input stream over $\Sigma = \{\tg{a}, \tg{b}, \tg{\#}\}$, and we want to output the average price of an $\tg{a}$-item at the end of each day. However, if there are no $\tg{a}$-items on a given day, we instead want to output the average from the previous day. A machine implementation of this is provided by $\DT_2$ in Figure~\ref{fig:dt-example-multipletransitions}.

\begin{figure}[t]
\centering \footnotesize
\fbox{\begin{minipage}{.48\textwidth}
\vspace{-2ex}
\[
Q = \{\texttt{sum}, \texttt{count}, \texttt{avg}, \texttt{prev\_avg}\}, \; I = \varnothing, \; F = \{\texttt{avg}\}
\]
\begin{align*}
\textsf{transitions}({\tg{i}}) =
    &\parallel{} \texttt{prev\_avg}' := 0 \\
\textsf{transitions}(\tg{a}) =
    &\parallel{} \texttt{sum}' := \texttt{prev\_avg} \cdot 0 + \curritem \\
    &\parallel{} \texttt{sum}' := \texttt{sum} + \curritem \\
    &\parallel{} \texttt{count}' := \texttt{prev\_avg} \cdot 0 + 1 \\
    &\parallel{} \texttt{count}' := \texttt{count} + 1 \\
\textsf{transitions}(\tg{b}) =
    &\parallel{} \texttt{sum}' := \texttt{sum} \\
    &\parallel{} \texttt{count}' := \texttt{count} \\
    &\parallel{} \texttt{prev\_avg}' := \texttt{prev\_avg} \\
\textsf{transitions}(\tg{\#}) =
    &\parallel{} \texttt{avg}' := \texttt{sum} \; / \; \texttt{count} \\
    &\parallel{} \texttt{avg}' := \texttt{prev\_avg} \\
    &\parallel{} \texttt{prev\_avg}' := \texttt{avg}'
\end{align*}
\end{minipage}}
\fbox{\begin{minipage}{.47\textwidth}
Example evaluation on input
\[
(\tg{b}, 2) (\tg{a}, 6) (\tg{b}, 2) (\tg{a}, 8) (\tg{a}, 7) (\tg{\#}, 0) (\tg{b}, 2) (\tg{\#}, 0) (\tg{a}, 7)(\tg{a}, 6).
\]
\[
\renewcommand{\arraystretch}{1.02}
\begin{array}{c|cccc}
    \trc{w}
        & \texttt{sum}
        & \texttt{count}
        & \texttt{avg}
        & \texttt{prev\_avg} \\
    \text{(input)} &&& \text{(output)} &\\
    \hline
    & \bot & \bot & \bot & 0 \\
    (\tg{b}, 2) & \bot & \bot & \bot & 0 \\
    (\tg{a}, 6) & 6 & 1 & \bot & \bot \\
    (\tg{b}, 2) & 6 & 1 & \bot & \bot \\
    (\tg{a}, 8) & 14 & 2 & \bot & \bot \\
    (\tg{a}, 7) & 21 & 3 & \bot & \bot \\
    (\tg{\#}, 0) & \bot & \bot & 7.0 & 7.0 \\
    (\tg{b}, 2) & \bot & \bot & \bot & 7.0 \\
    (\tg{\#}, 0) & \bot & \bot & 7.0 & 7.0 \\
    (\tg{a}, 7) & 7 & 1 & \bot & \bot \\
    (\tg{a}, 6) & 13 & 2 & \bot & \bot \\
\end{array}
\]
\end{minipage}}

\caption[Data transducer example 2.]{Data transducer $\DT_2$ monitoring the stream to produce, at the end of each day, either the average price of an $\tg{a}$-item (if there was at least one $\tg{a}$) or the previous average (if there was no $\tg{a}$). When there are multiple transitions $q' := t_1$ and $q' := t_2$, the semantics is such that we assign $q' := t_1 \sqcup t_2$.}
\label{fig:dt-example-multipletransitions}
\end{figure}

In $\DT_2$, \texttt{sum} and \texttt{count} store the sum of $\tg{a}$-items and number of $\tg{a}$-items on each day, respectively, and are defined only if there has been at least one $\tg{a}$. On the other hand, \texttt{prev\_avg} stores the previous average, but it is defined only if there has \emph{not} been any $\tg{a}$ yet. (We also initialize this to $0$ arbitrarily on the very first day.)
The state \texttt{avg} stores the output, and is only defined after a $\tg{\#}$ event. The logic of this computation involves two places where we need to have multiple transitions targeting a state. First, on receiving an $\tg{a}$, we set \texttt{sum} to be equal to the previous sum plus the current value, but we also set it to be equal to $0 \cdot \texttt{prev\_avg} + \curritem$. This works because exactly one of these two values will be defined, and the other will be $\bot$: either we have seen an $\tg{a}$ already, in which case we can update the sum, or we haven't seen one yet, in which case \texttt{prev\_avg} is still defined. Second, the overall output \texttt{avg} has two possible values, either $\texttt{sum} / \texttt{count}$ or $\texttt{prev\_avg}$, and again, exactly one of these two values will be defined, and the other will be $\bot$.
Thus, we have designed $\DT_2$ so that each union operation ($\sqcup$) never produces a conflict ($\top$).

\paragraph*{Combining output from parallel threads of computation.}
Our final example attempts to illustrate the feature which gives DTs their succinctness (see \S\ref{dt:sec:succinctness}): the ability to update multiple computations independently and then combine their results. Suppose we want to compute, at the end of each day, the difference between the maximum price of $\tg{a}$ and the maximum price of $\tg{b}$, if there was at least one $\tg{a}$ and at least one $\tg{b}$. The DT $\DT_3$ in Figure~\ref{fig:dt-example-parallel} implements this computation.
The state \texttt{a\_init} of $\DT_3$ stores $0$ and is only defined if we haven't seen an $\tg{a}$ yet; similarly for \texttt{b\_init}.

\begin{figure}[t]
\centering \footnotesize
%%%% ONE COLUMN VERSION
% \fbox{\begin{minipage}{.98\textwidth}
% \[
% Q = \{\texttt{a\_init}, \texttt{a\_max}, \texttt{b\_init}, \texttt{b\_max}, \texttt{ab\_diff}\},\;
% I = \varnothing,\; F = \{\texttt{ab\_diff}\}
% \]
% \begin{align*}
% \textsf{transitions}({\tg{i}}) =
%     &\parallel{} \texttt{a\_init}' := 0
%             &\textsf{transitions}(\tg{b}) = &\parallel{} \texttt{b\_max}' := \texttt{b\_init} + \curritem \\
%     &\parallel{} \texttt{b\_init}' := 0
%             &&\parallel{} \texttt{b\_max}' := \max(\texttt{b\_max},\curritem) \\
% \textsf{transitions}(\tg{a}) =
%     &\parallel{} \texttt{a\_max}' := \texttt{a\_init} + \curritem
%             &\textsf{transitions}(\tg{\#}) =
%                 &\parallel{} \texttt{ab\_diff}' := \texttt{a\_max} - \texttt{b\_max} \\
%     &\parallel{} \texttt{a\_max}' := \max(\texttt{a\_max},\curritem)
%             &&\parallel{} \texttt{a\_init}' := 0 \\
%     &        &&\parallel{} \texttt{b\_init}' := 0
% \end{align*}
% \end{minipage}}

%%%% VERSION OF FIGURE WITH TWO-COLUMN ATTEMPT
\fbox{\begin{minipage}{.45\textwidth}
\vspace{-2ex}
\begin{align*}
Q &= \{\texttt{a\_init}, \texttt{a\_max}, \texttt{b\_init}, \texttt{b\_max}, \texttt{ab\_diff}\} \\
I &= \varnothing,\; F = \{\texttt{ab\_diff}\}
\end{align*}
\begin{align*}
\textsf{transitions}({\tg{i}}) =
    &\parallel{} \texttt{a\_init}' := 0 \\
    &\parallel{} \texttt{b\_init}' := 0 \\
\textsf{transitions}(\tg{a}) =
    &\parallel{} \texttt{a\_max}' := \texttt{a\_init} + \curritem \\
    &\parallel{} \texttt{a\_max}' := \max(\texttt{a\_max},\curritem) \\
    &\parallel{} \texttt{b\_max}' := \texttt{b\_max} \\
    &\parallel{} \texttt{b\_init}' := \texttt{b\_init} \\
\textsf{transitions}(\tg{b}) =
    &\parallel{} \texttt{b\_max}' := \texttt{b\_init} + \curritem \\
    &\parallel{} \texttt{b\_max}' := \max(\texttt{b\_max},\curritem) \\
    &\parallel{} \texttt{a\_max}' := \texttt{a\_max} \\
    &\parallel{} \texttt{a\_init}' := \texttt{a\_init} \\
\textsf{transitions}(\tg{\#}) =
    &\parallel{} \texttt{ab\_diff}' := \texttt{a\_max} - \texttt{b\_max} \\
    &\parallel{} \texttt{a\_init}' := 0 \\
    &\parallel{} \texttt{b\_init}' := 0
\end{align*}
\end{minipage}}
\fbox{\begin{minipage}{.5\textwidth}
Example evaluation on input
\[
(\tg{b}, 2) (\tg{a}, 6) (\tg{b}, 3) (\tg{b}, 1) (\tg{a}, 8) (\tg{\#}, 0) (\tg{b}, 2) (\tg{\#}, 0) (\tg{a}, 7) (\tg{b}, 1).
\]
\[
\renewcommand{\arraycolsep}{3pt}
\renewcommand{\arraystretch}{1.33}
\begin{array}{c|ccccc}
    \trc{w}
        & \texttt{a\_init}
        & \texttt{a\_max}
        & \texttt{b\_init}
        & \texttt{b\_max}
        & \texttt{ab\_diff} \\
    \text{(input)} &&&&& \text{(output)} \\
    \hline
    & 0 & \bot & 0 & \bot & \bot \\
    (\tg{b}, 2) & 0 & \bot & \bot & 2 & \bot \\
    (\tg{a}, 6) & \bot & 6 & \bot & 2 & \bot \\
    (\tg{b}, 3) & \bot & 6 & \bot & 3 & \bot \\
    (\tg{b}, 1) & \bot & 6 & \bot & 3 & \bot \\
    (\tg{a}, 8) & \bot & 8 & \bot & 3 & \bot \\
    (\tg{\#}, 0) & 0 & \bot & 0 & \bot & 5 \\
    (\tg{b}, 2) & 0 & \bot & \bot & 2 & \bot \\
    (\tg{\#}, 0) & 0 & \bot & 0 & \bot & \bot \\
    (\tg{a}, 7) & \bot & 7 & 0 & \bot & \bot \\
    (\tg{b}, 1) & \bot & 7 & \bot & 1 & \bot \\
\end{array}
\]
\end{minipage}}

\caption[Data transducer example 3.]{Data transducer $\DT_3$ monitoring the stream to produce, at the end of each day, the difference between the maximum price of an $\tg{a}$-item and the maximum price of a $\tg{b}$-item.}
\label{fig:dt-example-parallel}
\end{figure}

\section{Constructions}
\label{dt:sec:constructions}

Our primary interest in the DT model is to support a variety of succinct \emph{composition operations} which are not simultaneously supported by any existing model. In particular, such composition operations can enable a quantitative monitoring language like \QREpast{} in \Cref{dt:sec:rm}: language constructs can be implemented by the compiler as constructions on DTs, rather like how (traditional) regular expressions are compiled to nondeterministic finite automata.

For example, suppose we have DTs implementing two functions $f, g: (\tags \times \data)^{*} \to \cdata$, and we would like to implement the function $f + g$, which applies $f$ and $g$ to the input stream and adds the results.
To do so, we copy the states of the transducers for $f$ and $g$,
and we initialize and update the states in parallel (they do not interfere).
Then, we provide a new final state, and a single new transition which says that the new final state should be assigned the value of the final state of $f$ plus the value of the final state of $g$.
This works for every operation, and not just $+$: the combination of $k$ computations by applying a $k$-ary operation $\op \in \ops_k$ can be implemented by a corresponding $k$-ary construct on the $k$ underlying DTs. Moreover, the size of the DT will only be the sum of the sizes of the $k$ DTs, plus a constant.
In contrast, even this simple operation $f+g$ is not succinctly implementable using the most natural existing alternative to DTs, Cost Register Automata (see \Cref{dt:sec:succinctness}).

This construction for $f+g$ requires no assumptions about the DTs implementing $f$ and $g$.
However, not all operations are this straightforward.
Consider the following quantitative generalization of concatenation. Given $f: (\Sigma \times \data)^{*} \to \cdata$, $g: (\Sigma \times \data)^{*} \to \cdata$, and $\op \in \ops_2$, we wish to implement $\splitQ(f,g,\op)$:
on input $\trc{w}$, split the input stream into two parts, $\trc{w} = \trc{u} \cdot \trc{v}$, such that $f(\trc{u}) \ne \bot$ and $g(\trc{v}) \ne \bot$ (respectively, $f$ matches $\trc{u}$ and $g$ matches $\trc{v}$), and return $\op(f(\trc{u}),g(\trc{v}))$. Assume that the decomposition of $\trc{w}$ into $\trc{u}$ and $\trc{v}$ such that $f(\trc{u}) \ne \bot$ and $g(\trc{v}) \ne \bot$ is unique.
In order to naively implement this operation, on an input string $\trc{w}$, we must not only keep track of the current
configuration of $f$ on $\trc{w}$,
but for \emph{every} split $\trc{w} = \trc{u} \trc{v}$ where $f$ matches $\trc{u}$,
we must keep track of the current configuration of $g$ on $\trc{v}$.
If there are many possible prefixes $\trc{u}$ of $\trc{w}$ such that $f(\trc{u}) \ne \bot$, we may have to keep arbitrarily many configurations of $g$. This naive approach is therefore impossible using only the finite space that a DT allows, if we treat $f$ and $g$ only as black boxes.
% , whose implementations lack additional structure.
% Indeed, it is possible to give examples of $f$ and $g$ which are efficiently implementable in the streaming setting, whereas $h = f \cdot g$ is not implementable without linear space in the input stream.

What we need to avoid this is an additional structural condition on $g$. Rather than keeping multiple copies of $g$, we would like to keep only a single configuration in memory: whenever the current prefix matches $f$, \emph{restart} $g$ with new data values on its initial states (keeping any current data values as well).
To motivate this idea, consider the analogous concatenation construction for two NFAs: every time the first NFA accepts, we are able to ``restart'' the second NFA by adding a token to its start state (we don't need an entirely new NFA every time).
This property for DTs is called \emph{restartability}.
Restartable DTs are an equally expressive subclass
consisting of those DTs for which restarting computation on the same transducer does not cause interference in the output.

The set of strings that a DT ``matches'' is captured by its \emph{extended language}, defined in \Cref{dt:subsec:dt-regularity}. Correspondingly, we assume that whenever a DT is restarted, the new initial vector is either all $\bot$, or all \emph{not} $\bot$ (in $\data \cup \{\top\}$). If the \emph{output} of a DT also satisfies this property (on every input it is either all $\bot$, or all \emph{not} $\bot$), then we say that the DT is \emph{output-synchronized}. This property is required in the concatenation and iteration constructions, but it is not as crucial to the discussion as restartability.

We begin in \Cref{dt:subsec:constructions-general} by giving general constructions that do not rely on restartability. We highlight the implemented semantics, the extended language, and the size of the constructed DT in terms of its constituent DTs.
Then in \Cref{dt:subsec:constructions-restartable}, we define restartability and use it to give succinct constructions for unambiguous parsing operations, namely \emph{concatenation} and \emph{iteration}.
Moreover, we show that (under certain conditions) our operations \emph{preserve} restartability, thus enabling modular composition using the restartable DTs. We also show that checking restartability is hard (PSPACE-complete), and we mention converting a non-restartable DT to a restartable one, but with exponential blowup.

\subsection{General Constructions}
\label{dt:subsec:constructions-general}

\paragraph*{Notation}
It is convenient to introduce shorthand $(\varepsilon, X, q', t)$ for the union of $|\Sigma| + 1$ transitions: $(\sigma, X, q', t)$ for every $\sigma \in \Sigma \cup \{{\tg{i}}\}$. Because this includes an initial transition, this requires that $X \subseteq \states'$ and that $\curritem$ does not appear in $t$. We call such a collection of transitions an \emph{epsilon transition} because, like epsilon transitions from classical automata, the transition may produce a value at its target state on the empty data word and on every input character.

For readability, we abbreviate the type of a DT
$\DT: \cdata^I \times (\Sigma \times D)^* \to \cdata^F$ as $\DT: \DTtype{I}{F}$.
This can be thought of as a function from input variables $I$ of type $\cdata$ to output variables $F$ of type $\cdata$, which also consumes some data word in $(\Sigma \times D)^*$ as a side effect.
For sets of variables (or states) $X_1, X_2$, when we write $X_1 \cup X_2$ we assume that the union is disjoint, unless otherwise stated.

We also define a \emph{data function} to be a plain function $\cdata^I \to \cdata^F$ which is
% equal to some composition of operations in $\ops$. Such a function can be
given by a collection of one or more terms $t : \tms[I]$ for each $f \in F$ (the output value of $f$ is then the union of the values of all terms). If $\DF \subseteq F \times \tms[I]$, then we write $\DF: \DFtype{I}{F}$ to abbreviate the semantics $\sem{\DF}: \cdata^I \to \cdata^F$.
The \emph{size} of $\DF$ is the total length of description of all of the terms $t$ it contains.

\paragraph*{Parallel composition.}
Suppose we are given two DTs $\DT_1 = \DTtuplesub{1}$ and $\DT_2 = \DTtuplesub{2}$, and assume that the sets of initial states are the same up to some implicit bijections $\pi_1: I \to I_1$, $\pi_2: I \to I_2$, for a set $I$ with $|I| = |I_1| = |I_2|$. (It is always possible to benignly extend both DTs with extra initial states so that they match, so this assumption is not restrictive.)
We wish to define a DT which feeds the input $(\trc{x},\trc{w})$ into both DTs in parallel. To do so, we define $\DT = \parcompDT{\DT_1}{\DT_2}$ to be the tuple $\DTtuple{}$, where $Q = Q_1 \cup Q_2 \cup I$, $F = F_1 \cup F_2$, and
\begin{align*}
\Delta = \Delta_1 \cup \Delta_2
    \cup \big\{(\varepsilon, i', \pi_1(i)', i') : i \in I \big\}
    \cup \big\{(\varepsilon, i', \pi_2(i)', i') : i \in I \big\}.
\end{align*}
Here, the transitions we added (those in $\Delta$ but not in $\Delta_1$ or $\Delta_2$) \emph{copy} values from $I$ into both $I_1$ and $I_2$. This is only relevant on initialization $\update_{\tg{i}}$, since after that states $I$ will not be defined, but we used an epsilon transition instead of just an ${\tg{i}}$ transition to preserve restartability, which will be discussed in \Cref{dt:subsec:restartability}. Since we added no other transitions, the least fixed point Equation~\eqref{dt:eq:fixpoint-semantics} defining the next (or initial) configuration decomposes into the least fixed point on states $Q_1$, and on states $Q_2$. It follows that the semantics satisfies $\sem{\DT}(\trc{x},\trc{u}) = (\sem{\DT_1}(\trc{x},\trc{u}),\sem{\DT_2}(\trc{x},\trc{u}))$. Here, $(\trc{y}_1,\trc{y}_2)$ denotes the vector $\trc{y} \in \cdata^F$ that is $\trc{y}_1$ on $F_1$ and $\trc{y}_2$ on $F_2$.
Parallel composition is commutative and associative.
The utility of parallel composition is that it allows us to combine the outputs $\trc{y}_1$ and $\trc{y}_2$ later on. This is accomplished by \emph{concatenation} with another DT which combines the outputs (\Cref{dt:subsec:constructions-restartable}).

\begin{figure}[H]
\begin{dtbox}
\textbf{Parallel composition.}
If $\DT_1: \DTtype{I}{F_1}$ and $\DT_2: \DTtype{I}{F_2}$,
then $\parcompDT{\DT_1}{\DT_2} : \DTtype{I}{F_1 \cup F_2}$ satisfies
% implements the semantics
\[
\sem{\parcompDT{\DT_1}{\DT_2}}(\trc{x},\trc{w}) = (\sem{\DT_1}(\trc{x},\trc{w}),\sem{\DT_2}(\trc{x},\trc{w})),
\]
such that $\size{\parcompDT{\DT_1}{\DT_2}} = \size{\DT_1} + \size{\DT_2} + O(|I|)$.
It therefore matches the set of tag strings
$\clang(\parcompDT{\DT_1}{\DT_2}) = \clang(\DT_1) \cap \clang(\DT_2)$.
\end{dtbox}

\label{dt:fig:parallel-composition}
\end{figure}

\paragraph*{Union.}
Suppose we are given DTs $\DT_1 = \DTtuplesub{1}$ and $\DT_2 = \DTtuplesub{2}$, and assume that the sets of initial and final states are the same up to some bijections: $\pi_1: I \to I_1$, $\pi_2: I \to I_2$, $\rho_1: F \to F_1$, $\rho_2: F \to F_2$, for sets $I$ and $F$ with $|I| = |I_1| = |I_2|$ and $|F| = |F_1| = |F_2|$. We wish to define a DT which feeds the input $(\trc{x},\trc{w})$ into both DTs in parallel and returns the union $(\sqcup)$ of the two results.
We define $\DT = \union{\DT_1}{\DT_2} = \DTtuple{}$ by $Q = Q_1 \cup Q_2 \cup I \cup F$ and
\begin{alignat*}{2}
\Delta = \Delta_1 \cup \Delta_2
    &\cup \big\{(\varepsilon, i', \pi_1(i)', i') : i \in I \big\}
    &&\cup \big\{(\varepsilon, i', \pi_2(i)', i') : i \in I \big\} \\
    &\cup \big\{(\varepsilon, \rho_1(f)', f', \rho_1(f)') : f \in F \big\}
    &&\cup \big\{(\varepsilon, \rho_2(f)', f', \rho_2(f)') : f \in F \big\}.
\end{alignat*}

Similar to the parallel composition construction, the additional transitions here ensure that we copy values from $I$ into $I_1$ and $I_2$, and copy values from $F_1$ and $F_2$ into $F$, whenever these values are defined. In particular, on initialization the initial vector $\trc{x}$ will be copied into $I_1$ and $I_2$, and on every data word the output values $\trc{y}_1$ and $\trc{y}_2$ of $\DT_1$ and $\DT_2$ will be copied into the \emph{same} set of final states, so that they have to be joined by $\sqcup$. In particular, if both $\trc{y}_1$ and $\trc{y}_2$ are defined, the output will be $\top$. We see therefore that the semantics is such that $\sem{\DT}(\trc{x},\trc{u}) = \sem{\DT_1}(\trc{x},\trc{u}) \sqcup \sem{\DT_2}(\trc{x},\trc{u})$. Like parallel composition, union is commutative and associative.

\begin{figure}[H]
\begin{dtbox}
\textbf{Union.}
If $\DT_1: \DTtype{I}{F}$ and $\DT_2: \DTtype{I}{F}$,
then $\union{\DT_1}{\DT_2} : \DTtype{I}{F}$
implements the semantics
\[
\sem{\union{\DT_1}{\DT_2}}(\trc{x},\trc{w}) = \sem{\DT_1}(\trc{x},\trc{w}) \sqcup \sem{\DT_2}(\trc{x},\trc{w}),
\]
s.t. $\size{\union{\DT_1}{\DT_2}} = \size{\DT_1} + \size{\DT_2} + O(|I| + |F|)$.
It matches
$\clang(\union{\DT_1}{\DT_2}) = \clang(\DT_1) \cup \clang(\DT_2)$.
\end{dtbox}

\label{dt:fig:union}
\end{figure}

\paragraph*{Prefix summation.}
Now we consider a more complex operation. Suppose we are given $\DT_1 = \DTtuplesub{1}$, and a data word $\trc{w}$, such that the output on the empty data word is $\trc{y}^{(0)}_1$, the output after receiving one character of the data word is $\trc{y}^{(1)}_1$, and in general the output after $k$ characters is $\trc{y}^{(k)}_1$. The problem is to return the \emph{sum} of these outputs: we want a DT that returns $\trc{y}^{(i)} = \trc{y}^{(0)}_1 + \cdots + \trc{y}^{(i)}_1$ after receiving $i$ characters. This is called the \emph{prefix sum} because $\trc{y}^{(k)}_1$ is the value of $\DT$ on the $k$th prefix of the data word.
In general, instead of $+$, we can take an arbitrary operation which folds the outputs of $\DT_1$ on each prefix. We suppose that this operation is given by a data function $\DF$ which, for some set $F$, is a function $\cdata^{F \cup F_1} \to \cdata^{F}$. It takes the previous ``sum'' $\trc{y}^{(i-1)} \in \cdata^F$, combines it with the new output of $\DT_1$, $\trc{y}_1^{(i)} \in \cdata^{F_1}$, and produces the next ``sum'' $\trc{y}^{(i)} \in \cdata^F$. So, we'll have $G(\trc{y}^{(i-1)},\trc{y}_1^{(i)}) = \trc{y}^{(i)}$. We want a DT that, on input initial values for $I_1$ and initial values $\trc{y}^{(-1)}$ for $F$, will return $\trc{y}^{(i)}$.
%% Would like to add this space back..
Formally, we convert $\DF$ to a DT $\DT_2 = \DTtuplesub{2}$, with bijections $\pi: (F \cup F_1) \to I_2$, $\rho: F \to F_2$, which only contains epsilon-transitions: for each term $t$ in $G$ with variables $P \subseteq (F \cup F_1)$ giving a value of $f \in F$, we create an epsilon transition $(\varepsilon, \pi(P)', \rho(f)', t)$. Then we define the prefix sum $\prefixsum{\DT_1}{\DF} = (Q, \Sigma, \Delta, (I_1 \cup F), F_2)$, where $Q = Q_1 \cup Q_2 \cup F$ and
\begin{align*}
\Delta = \Delta_1 \cup \Delta_2
    &\cup \big\{(\varepsilon, f_1', \pi(f_1)', f_1') : f_1 \in F_1 \big\} \\
    &\cup \big\{(\varepsilon, f', \pi(f)', f') : f \in F \big\}
    \quad \cup \big\{(\sigma, \rho(f), \pi(f)', \rho(f)) : f \in F, \sigma \in \Sigma \big\}.
\end{align*}

First on the empty data word, the outputs $F_2'$ of $\DT_1$ and the initial vector in $F'$ are copied into $I_2$, and $\DT_2$ produces the correct output $\trc{y}^{(0)} = \sem{\DF}(\trc{y}^{(-1)},\trc{y}_1^{(0)})$. Now, when we read in a character in $\Sigma \times \data$, the final states $F_2'$ flow back into inputs to $\DT_2$, and the new output of $\DT_1$ also flows in. Because the machine $\DT_2$ was constructed to be just a set of epsilon-transitions from $I_2$ to $F_2$, it does not save any internal state, but just computes the output in terms of the input again. So the next output will be $\sem{\DF}(\trc{y}^{(0)},\trc{y}_1^{(1)})$, and then $\sem{\DF}(\trc{y}^{(1)},\trc{y}_1^{(2)})$, and so forth.
% The extended language of matched strings depends on $\DF$; we do not write it out explicitly.

\begin{figure}[H]
\begin{dtbox}
\textbf{Prefix sum.}
If $\DT_1: \DTtype{I}{Z}$
and $\DF: \DFtype{F \cup Z}{F}$,
then $\prefixsum{\DT_1}{\DF}: \DTtype{I \cup F}{F}$
implements the semantics
\begin{align*}
\sem{\prefixsum{\DT_1}{\DF}}((\trc{x},\trc{y}),\varepsilon)
    &= \sem{\DF}(\trc{y},\sem{\DT_1}(\trc{x},\varepsilon)) \\
\sem{\prefixsum{\DT_1}{\DF}}((\trc{x},\trc{y}),\trc{w} (\sigma,d))
    &= \sem{\DF}(\sem{\prefixsum{\DT_1}{\DF}}((\trc{x},\trc{y}),\trc{w}),\sem{\DT_1}(\trc{x},\trc{w} (\sigma,d)))
\end{align*}
such that $\size{\prefixsum{\DT_1}{\DF}} = \size{\DT_1} + \size{\DF} + O(|Z| + |F|)$.
\end{dtbox}

\label{dt:fig:prefix-sum}
\end{figure}

\paragraph*{Conditioning on undefined and conflict values.}
A DT that is constructed using the other operations---particularly union, and concatenation and iteration from \Cref{dt:subsec:constructions-restartable}---may produce undefined ($\bot$) or conflict ($\top$) on certain inputs. In such a case, we may want to perform a computation which \emph{conditions} on whether the output is undefined, defined or conflict: for instance, we may want to produce $1$ if there is a conflict, or we may want to replace all $\bot$ and $\top$ outputs with concrete data values. (In particular, in \Cref{dt:sec:rm}, we will want to replace $\bot$ and $\top$ with Boolean values.) We give a construction for this purpose. To simplify the problem, suppose that we are given $\DT_1 = \DTtuplesub{1}$, and we want to construct a DT $\DT_\bot$ with no initial states, the same set of final states, and the following behavior: for all $\trc{x} \in \data^{\init_1}$ (\emph{not} $\cdata^{\init_1}$), all $\trc{u} \in (\Sigma \times \data)^{*}$, and all $f_1 \in \final_1$, if $\sem{\DT_1}(\trc{x},\trc{u})(f_1) = \bot$ then $\sem{\DT_\bot}(\trc{u})(f_1) \in \data$, and otherwise, $\sem{\DT_\bot}(\trc{u})(f_1) = \bot$. Here, since $I = \varnothing$, the first argument is omitted. We similarly want to define $\DT_\data$ which is in $\data$ if $\DT_1$ is in $\data$, and $\bot$ otherwise, and $\DT_\top$ which is in $\data$ if $\DT_1$ is $\top$, and $\bot$ otherwise.
So that $\data$ is not empty, we assume that there is some constant operation in $\ops_0$, say $d_\one$ (so $d_\one \in \data$).

The idea of the construction is that we replace $Q_1$ with $Q_1 \times \{\bot, \one,\top\}$. For each state $q \in Q_1$, at all times, exactly one of $(q, \bot)$, $(q, \one)$, and $(q, \top)$ will be $d_\one$ and the other two will be $\bot$. Which state is $d_\one$ should correspond to whether $q$ was undefined, defined, or conflict. (This is adapted from the classic trick of dealing with negation by replacing all values with pairs of either (true, false) or (false, true).) However, in order for this to work without blowup our DT needs to be \emph{acyclic}. Therefore we begin with a preliminary stage of converting the DT to acyclic. Observe that in the semantics of \Cref{dt:subsec:dt-semantics}, iterating the assignment~\eqref{dt:eq:fixpoint-semantics} $2n$ times would be sufficient to reach the fixed point, where $n$ is the number of states of the DT. So we create $2n$ copies of the states of the DT, with one set of transitions from each copy to the next. In this preliminary stage the size of the transducer may be \emph{squared}, i.e. there is quadratic blowup. Now assuming $\DT$ is acyclic, for each variable $q' \in Q_1'$, whether $q'$ is undefined, defined, or conflict is a Boolean function of all the source states of transitions that target $q'$; this function can be built as a Boolean circuit by adding intermediate states and intermediate transitions, in number at most the total size of the transitions targeting $q'$.
$\DT_\bot$, $\DT_\data$, and $\DT_\top$ differ only in which states are final---$F_1 \times \{\bot\}$, $F_1 \times \{\one\}$, and $F_1 \times \{\top\}$, respectively.

%% Original, extended explanation
% For the first stage, we recall the naive evaluation approach in \S{}2.3. The idea was that we could iterate the fixed-point computation at most $2n$ times, where $n$ is the number of states of the DT, to reach the fixed point. To make the transducer acyclic, then, we just need $2n$ copies of the states. We take states $Q_1 \times \{1,2,\ldots,2n\}$, and copy the transitions to go from $Q_1 \times \{i\}$ to $Q_1 \times \{i+1\}$ for every $i$. This will clearly be cyclic and the final values of $Q_1 \times \{2n\}$ are the desired fixed point given in Equation~1. We have to make sure that when we refer to a previous (non-primed) state variable, that is always a value in $Q_1 \times \{2n\}$.
%

% For the second stage, we do not directly preserve the semantics of the DT, but only whether each state is undefined, defined, or conflict on every input. First, for every transition $(\sigma, X, q', t)$, suppose that $X = \{x_1, x_2, \ldots, x_k\}$. Then we create $k$ intermediate states $q_1, q_2, q_3, \ldots, q_k$, where $q_k = q$ and $q_i$ represents the value of a transition with source variables $\{x_1, \ldots, x_i\}$. Specifically, we replace the transition itself with $k$ intermediate transitions $e_1, e_2, e_3, \ldots, e_k$, where $e_1 = (\sigma, x_1, q_1', x_1)$, and for $i \ge 2$, $e_i = (\sigma, \{x_i, q_{i-1}'\}, q_i', x_i')$. Then, observe that whether $q_k = q$ is undefined, defined, or conflict is preserved by this transformation. If $X = \varnothing$, we can just replace $(\sigma, \varnothing, q', t)$ with $(\sigma, \varnothing, q', d_\one)$, where $d_\one$ is a constant. Now each transition has at most two source variables. Next, consider a state $q'$ which is the target variable for $k$ transitions. We similarly replace $q'$ with a sequence of states $q_1, q_2, \ldots, q_k$, each of which is the target of only two transitions ($q_{k-1}$ and one of the $k$ original transitions). Overall, the total size of the transducer for this stage multiples by a constant.

% Now we are finally ready to look at the third stage. Assume we now have $\DT_1 = \DTtuplesub{1}$ which is acyclic, and in which every state is the target of at most two transitions, which each have at most two source variables.
% We define three DTs, $\isbot{\DT_1}$, $\isdef{\DT_1}$, and $\istop{\DT_1}$. All of them have $Q = Q_1 \times \{\bot, \one, \top\}$, $I = \varnothing$, and the same set of transitions $\Delta$, but the set of final states for the three constructions is $F_1 \times \{\bot\}$, $F_1 \times \{\one\}$, and $F_1 \times \{\top\}$, respectively. Now we want to encode the transitions $\Delta$. For every state $q'$, we know that there are at most two transitions targeting it with at most two source variables each; so we can build a table of the \emph{value} of $q'$ given the \emph{values} of the (at most) four source variables, where ``value'' means one of $\bot, \one,$ or $\top$. This is a table with $3^4$ entries. For each entry, we make an appropriate transition: for instance, if $q'$ is $\one$ on source variables $x_1 = \bot$, $x_2 = \top$, and $x_3 = \top$, then we make a transition $(\sigma, \{(x_1,\bot), (x_2,\top), (x_3,\top)\}, (q',\one), d_\one)$. This results in a constant number of transitions for each original transition ($81$, but a more careful analysis gives $9$). We also need to initialize the states correctly. In addition to converting the initial transitions, we add initial transitions $({\tg{i}}, \varnothing, (q',\one), d_\one)$ for each $q \in I$, so that each initial state is initially designated $\one$ (a value in $\data$).

\begin{figure}[H]
\begin{dtbox}
\textbf{Support.}
Let $d_\one \in \data$.
If $\DT_1: \DTtype{I}{F}$,
then
$\isbot{\DT_1}: \DTtype{\varnothing}{F}$, $\isdef{\DT_1}: \DTtype{\varnothing}{F}$, and $\istop{\DT_1}: \DTtype{\varnothing}{F}$.
These constructions implement the following semantics.
For all $f \in F$:
\begin{align*}
\sem{\isbot{\DT_1}}(\trc{w})(f)
    &= d_{\one} \text{ if } \sem{\DT_1}(\trc{x},\trc{w})(f) = \bot \;\;\forall \trc{x} \in \data^{I}; \quad\bot \text{ otherwise} \\
\sem{\isdef{\DT_1}}(\trc{w})(f)
    &= d_{\one} \text{ if } \sem{\DT_1}(\trc{x},\trc{w})(f) \in \data \;\;\forall \trc{x} \in \data^{I}; \quad\bot \text{ otherwise} \\
\sem{\istop{\DT_1}}(\trc{w})(f)
    &= d_{\one} \text{ if } \sem{\DT_1}(\trc{x},\trc{w})(f) = \top \;\;\forall \trc{x} \in \data^{I}; \quad\bot \text{ otherwise}
\end{align*}
such that $\size{\isbot{\DT_1}} = O(\size{\DT_1}^2)$ and likewise for the other two. Alternatively, if $\DT_1$ is acyclic, the size will only be $O(\size{\DT_1})$.
\end{dtbox}

\label{dt:fig:support}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Unambiguous Parsing and Restartability}
\label{dt:subsec:constructions-restartable}
\label{dt:subsec:restartability}

We now want to capture the idea of restartability---that multiple threads of computation may be replaced by updates to a single configuration---with a formal definition. Recall the example in the introduction of $\splitQ(f,g,\op)$.
During the execution of $f$ on input $\trc{w}$, whenever the current prefix $\trc{u}$ of $\trc{w}$ matches, i.e. $f(\trc{u}) \ne \bot$, we could (naively and inefficiently) implement $\splitQ(f,g,\op)$ by keeping a separate configuration (thread) of $g$ from that point forward. For example, suppose that $\trc{w} = ({\tg{a}}, d_1) ({\tg{b}}, d_2) ({\tg{a}}, d_3) ({\tg{a}}, d_4)$, and that the output of $f$ is defined after receiving each ${\tg{a}}$-item, and undefined otherwise. Then $f$ is defined on input $({\tg{a}}, d_1)$, on $({\tg{a}}, d_1)({\tg{b}}, d_2)({\tg{a}}, d_3)$, and on $({\tg{a}}, d_1)({\tg{b}}, d_2)({\tg{a}}, d_3)({\tg{a}}, d_4)$. Corresponding to these three inputs, we would have three threads of $g$: $\trc{c}_1$ on input $({\tg{b}}, d_2) ({\tg{a}}, d_3) ({\tg{a}}, d_4)$, $\trc{c}_2$ on input $({\tg{a}}, d_4)$, and $\trc{c}_3$ on input $\varepsilon$. Suppose that each configuration $\trc{c}_i$ includes an final state with the value of $\trc{y}_i = \op(f(\trc{u}),g(\trc{v}))$.
The value of $\splitQ(f,g,\op)$ could then be computed as the \emph{union} of the outputs from all these threads:
$\splitQ(f,g,\op)(\trc{w}) = \trc{y}_1 \sqcup \trc{y}_2 \sqcup \trc{y}_3.$
We apply the union here because we expect the split $\trc{w} = \trc{u} \cdot \trc{v}$, where $\trc{u} \in \clang(f)$ and $\trc{v} \in \clang(g)$, to be unique. Thus all but at most one of $\trc{y}_i$ will be $\bot$, and the union gives us the unique answer (if any).

A DT will be called restartable if a \emph{single configuration} $\trc{c}$ can \emph{simulate} the behavior of these several configurations $\trc{c}_1, \trc{c}_2$, and $\trc{c}_3$. This is a relation between configurations of $g$ and an arbitrarily long sequence of configurations of $g$ (we could have used a multiset instead of a sequence). The relation $\trc{c} \sim [\trc{c}_1, \trc{c}_2, \trc{c}_3]$ is intended to capture that $\trc{c}$ is observationally indistinguishable from the sequence $\trc{c}_1, \trc{c}_2, \trc{c}_3$. For starters, we require that the output is the same: if $\trc{y}$ is the output of $\trc{c}$, then $\trc{y} = \trc{y}_1 \sqcup \trc{y}_2 \sqcup \trc{y}_3$. But we also require that the simulation is preserved when we update the sequence of configurations of $g$, by reading in a new input character and/or starting a new thread. The definition allows the simulation to be undefined on configurations that are never reachable in an actual execution---it need not be true that \emph{every} sequence $[\trc{c}_1, \ldots, \trc{c}_k]$ is simulated by some $\trc{c}$, but it should be true that every sequence that can be reached by a series of updates is simulated.

With this intuition, the simulation relation on configurations of $g$ should satisfy the following properties (see the definition below). Property (i) addresses the base case before any input characters are received (i.e. initialization ${\tg{i}}$). Suppose that on initialization, the machine for $g$ is started with $k \ge 0$ threads, given by initial vectors $\trc{x}_1, \ldots, \trc{x}_k$. (In our example, these threads would arise as the output of $f$ on initialization.) Then the configuration in a single copy of $g$ on input $\trc{x}_1 \sqcup \cdots \sqcup \trc{x}_k$ should simulate the behavior of $k$ separate copies of $g$. Property (ii) requires that the simulation then be preserved as input characters are read in. Suppose that $\trc{c} \sim [\trc{c}_1, \ldots, \trc{c}_k]$, and we now read in a character $(\sigma,d)$ to $g$. Simultaneously, we start zero or more new threads represented by the vector $\trc{x}$ (e.g., $\trc{x}$ is the new output produced by $f$ on input $(\sigma, d)$). Then if we update and re-initialize the initial states of $\trc{c}$ with $\trc{x}$, that configuration should simulate updating each $\trc{c}_i$ separately, \emph{and} adding one or more new threads represented by $\trc{x}$. Finally, property (iii) says that our simulation is sound: for every configuration which simulates a sequence of configurations, the output of the one configuration is equal to the union of the sequence of outputs.

For property (ii) in particular, we need to define what it means to update a configuration $\trc{c}$ and simultaneously restart new threads by placing values $\trc{x}$ on the initial states $I'$. (Such an update function is only needed for the simulating configuration, not the sequence of simulated configurations.) For each $\sigma \in \tags$ and for every $\trc{x} \in \cdata^\init$ we define a generalized evaluation function $\update_{\sigma,\trc{x}}: \cdata^\states \times \data \to \cdata^\states$. This represents executing $\update_\sigma$ and then starting \emph{zero or more} new threads, by initializing the new initial states with $\trc{x}$. We modify the least fixed point definition of $\trc{c}'$ in Equation~\ref{dt:eq:fixpoint-semantics}) to include the new initialization on states $I'$: $\trc{c}'$ is the least vector satisfying
\[
\trc{c}'(q') = \trc{x}(q) \sqcup \bigsqcup_{(\sigma, X, q', t) \in \update} \sem{t}(\trc{c}'|_X),
\]
where $\trc{x}(q) = \bot$ if $q \notin \init$. This resembles the way we already incorporated $\trc{x}$ into the definition of $\update_{\tg{i}}$.
We restrict the vector $\trc{x}$ in each restart to be in the space $\mathcal{X} = \{\bot\}^\init \cup (\data \cup \{\top\})^\init$, which is closed under $\sqcup$.
Let $\vec{\bot}$ be the vector with every entry equal to $\bot$.

\begin{definition}[Restartability]
\label{dt:definition:restartability}
Let $\DT = \DTtuple$ be a DT over signature $(\data, \ops)$;
let $C = \cdata^\states$ be the set of configurations of $\DT$, and
$[C]$ the set of \emph{finite lists} of configurations of $\DT$.
Let $\mathcal{X} = \{\bot\}^\init \cup (\data \cup \{\top\})^\init$ be the set of possible initializations for a restarted thread.
$\DT$ is \emph{restartable} if there exists a binary relation $\sim \subseteq C \times [C]$
(called a ``simulation'') with the following properties:
\begin{enumerate}
\item[i.] \textbf{(Base case)}
  For all $\trc{x}_1, \ldots, \trc{x}_k \in \mathcal{X}$,
  $\update_{{\tg{i}}}\left(\bigsqcup_{i=1}^k \trc{x}_i\right) \sim [\update_{{\tg{i}}}(\trc{x}_1),\ldots,\update_{{\tg{i}}}(\trc{x}_k)]$. (If $k = 0$, we get $\update_{{\tg{i}}}(\vec{\bot}) \sim []$, where $[] \in [C]$ denotes the empty list.)
\item[ii.]
  \textbf{(Update with restarts)} For all $(\sigma, d) \in (\tags \times \data)$,
  for all $x \in \mathcal{X}$,
  and for all $\trc{c}$, $\trc{c}_1, \trc{c}_2, \ldots, \trc{c}_k$, $\hat{\trc{c}}_1, \hat{\trc{c}}_2, \ldots, \hat{\trc{c}}_l$,
  if $\trc{c} \sim [\trc{c}_1, \trc{c}_2, \ldots, \trc{c}_k]$
  and $\update_{{\tg{i}}}(\trc{x}) \sim [\hat{\trc{c}}_1, \hat{\trc{c}}_2, \ldots, \hat{\trc{c}}_l]$
  then
  \[\update_{\sigma,\trc{x}}(\trc{c},d) \sim [\update_{\sigma}(\trc{c}_1,d), \ldots, \update_{\sigma}(\trc{c}_k,d), \hat{\trc{c}}_1, \hat{\trc{c}}_2, \ldots, \hat{\trc{c}}_l].\]
\item[iii.]
  \textbf{(Implies same output)}
  If $\trc{c} \sim [\trc{c}_1, \trc{c}_2, \ldots, \trc{c}_k]$,
  and the output vectors for these configurations (extended data values at the final states) are $\trc{y}, \trc{y}_1, \trc{y}_2, \ldots, \trc{y}_k$, respectively, then we have $\trc{y} = \trc{y}_1 \sqcup \trc{y}_2 \sqcup \cdots \sqcup \trc{y}_k$.
\end{enumerate}
\end{definition}

A simple example (and counterexample) are in order. First, consider the following DT $\DT$ with two states: $Q = \{i,f\}$, $\Sigma = \{{\tg{a}},{\tg{b}}\}$, $I = \{i\}$, $F = \{f\}$, and one transition on input ${\tg{a}}$, $f' := i + \curritem$. The DT on input $(x,({\tg{a}},d))$ returns $x + d$, and on every other input is undefined. Then $\DT$ is restartable. We can represent configurations as ordered pairs $(x,y)$, where $x \in \cdata$ is the value of $i$ and $y \in \cdata$ is the value of $f$. We define that $\trc{c} \sim [\trc{c}_1, \ldots, \trc{c}_k]$ whenever $\trc{c} = \bigsqcup_{i=1}^k \trc{c}_i$. Then (i), (ii), and (iii) hold. For example, the base case says that $x = \bigsqcup_{i=1}^k x_k$, then $(x,\bot) \sim [(x_1,\bot), \ldots, (x_k,\bot)]$, which is true by definition.
% The crucial (iii) is also true by definition.
The intuition is that, in this simple case, we can say that a configuration of $\DT$ simulates a set of configurations (threads) if the configuration is the union of all those threads. The semantics just takes $(x,y)$ to $(z,x)$ on updating and restarting with $z$, so it preserves this relation.

For a counterexample, consider a DT $\DT$ which sums the value of a single initial state and the last ${\tg{a}}$: take $Q = \{i, f\}$, $I = \{i\}$, $F = \{f\}$, and the following transitions on input ${\tg{a}}$: $i' := i$, $f' := i' + \curritem$. We may represent configurations as $(x,y)$, for the values at $i, f$, respectively. To see this is not restartable, consider starting $\DT$ with a single input $x_1 \in \data$, then reading in $({\tg{a}},d)$ and starting a second input $x_2 \in \data$ (i.e. applying $\update_{{\tg{a}},x_2}$). Starting with $x_1$ results in the configuration $(x_1,\bot)$; then reading in $({\tg{a}},d)$ and starting with $x_2$ results in $(\top, \top)$. However, if $\DT$ were restartable, then by property (ii), we could instead read in $({\tg{a}},d)$ and add the second input $x_2$ separately: we thus would have $(\top,\top) \sim [(x_1,x_1+d),(x_2,\bot)]$. The problem is that this violates (iii): the output of $\DT$ is $\top$, which is not the same as $(x_1 + d) \sqcup \bot = x_1 + d$.

What is relevant for properties (i), (ii), and (iii) is actually only the configurations, input, and output \emph{up to equivalence}, i.e., where we replace $\cdata$ with $\{\bot, \one, \top\}$.
There are only finitely many configurations up to equivalence. This is why restartability is decidable (see Theorem~\ref{dt:thm:restartable-pspace-complete}).

\paragraph*{Concatenation}
Suppose we have two DTs $\DT_1 = \DTtuplesub{1}$ and $\DT_2 = \DTtuplesub{2}$, where $F_1$ and $I_2$ are the same up to bijection (say, $\pi: F_1 \to I_2$).
Now we want to compute the following parsing operation: on input $(\trc{x},\trc{w})$, consider all splits of $\trc{w}$ into two strings, $\trc{w} = \trc{w}_1 \trc{w}_2$. Apply $\DT_1$ to $(\trc{x},\trc{w}_1)$ to get a result $\trc{y}_1$, and apply $\DT_2$ to $(\trc{y}_1,\trc{w}_2)$ to get $\trc{y}_2$. Return the union ($\sqcup$) over all such splits of $\trc{y}_2$. In particular, assuming there is only one way to split $\trc{w} = \trc{w}_1 \trc{w}_2$ such that $\trc{y}_2$ does not end up being undefined, this operation splits the input string uniquely into two parts such that $\DT_1$ matches $\trc{w}_1$ and $\DT_2$ matches $\trc{w}_2$, and then applies $\DT_1$ and $\DT_2$ in sequence.

We implement this by taking $\DT = \concat{\DT_1}{\DT_2} = \DTtuple{}$ with $Q = Q_1 \cup Q_2$, $I = I_1$, $F = F_2$, and
\[
\Delta = \Delta_1 \cup \Delta_2 \cup \big\{(\varepsilon, \{f_1'\}, \pi(f_1)', f_1'): f_1 \in F_1 \big\}.
\]
The idea is very simple; every output of $\DT_1$ (i.e. a value produced at a state in $F_1$) should be copied into the corresponding initial state of $\DT_2$. This happens on initialization, and on every update. However, the semantics is not so simple, because every time we read in a character, $\DT_2$'s initial states $I_2$ are being re-initialized with new values (the values from $F_1$).

This ``re-initialization'' is exactly captured by our generalized update function $\update_{\sigma, \trc{x}}$ from earlier. Let us represent configurations of $\DT$ by $(\trc{c}_1, \trc{c}_2)$, where $\trc{c}_i$ is the component restricted to $Q_i$, i.e. the induced configuration of $\DT_i$.
Now consider an input $(\trc{x},\trc{w})$ to $\DT$.
We see that for the $i$th configuration of $\DT$ $(\trc{c}_1^{(i)},\trc{c}_2^{(i)})$, $\trc{c}_1^{(i)}$ is the same as the $i$th configuration of $\DT_1$ on input $(\trc{x},\trc{w})$.
Moreover, if $\trc{y}_1^{(i)}$ is the $i$th output of $\DT_1$, this is used to reinitialize $\DT_2$;
so we see that $\trc{c}_2^{(i)} = \update_{\sigma,\trc{y}_1^{(i)}}(\trc{c}_2^{(i-1)},d)$ (where this is the update function of $\DT_2$). The output $\trc{y}_2^{(i)} = \trc{c}_2^{(i)}|_F$ of $\DT_2$ is the output of $\DT$.

Assume that $\DT_1$ is \emph{output-synchronized}: this means that each $\trc{y}_1^{(i)} \in \mathcal{X}$, i.e., all values are $\bot$ or all values are in $\data \cup \{\top\}$. And assume that $\DT_2$ is \emph{restartable}. Then the simulation relation allows us to, at every step, replace $\trc{c}_2$ by a list of configurations where each configuration is $\DT_2$ on a different suffix of $\trc{w}$. In particular, we recursively replace $\update_{\sigma, \trc{y}_1^{(i)}}(\trc{c}_2^{(i-1)},d)$ with the list of configurations for $\update_\sigma(\trc{c}_2^{(i-1)},d)$ and a single new thread $\update_{\tg{i}}(\trc{y}_1^{(i)})$. Because $\trc{y}_1^{(i)} \in \mathcal{X}$, this is guaranteed by property (ii) of restartability. Property (iii) then implies the semantics given in the following summary.

\begin{figure}[H]
\begin{dtbox}
\textbf{Concatenation.}
Let $\DT_1: \DTtype{I}{Z}$ and $\DT_2: \DTtype{Z}{F}$,
such that $\DT_1$ is output-synchronized and $\DT_2$ is restartable.
Then $\concat{\DT_1}{\DT_2} : \DTtype{I}{F}$ implements the semantics
\[
\sem{\concat{\DT_1}{\DT_2}}(\trc{x},\trc{w}) = \bigsqcup_{\trc{w} = \trc{w}_1 \trc{w}_2} \sem{\DT_2}(\sem{\DT_1}(\trc{x},\trc{w}_1),\trc{w}_2).
\]
such that $\size{\concat{\DT_1}{\DT_2}} = \size{\DT_1} + \size{\DT_2} + O(|Z|)$.
It matches $\clang(\concat{\DT_1}{\DT_2}) = \clang(\DT_1) \cdot \clang(\DT_2)$.
\end{dtbox}

\label{dt:fig:concatenation}
\end{figure}

\paragraph*{Concatenation with data functions.}

A special case of concatenation can be described which does \emph{not} require restartability, and which we use in \Cref{dt:sec:rm}. Suppose we are given $\DT_1 = \DTtuplesub{1}$ and we want to concatenate with a data function $\DF_2: \DFtype{F_1}{F_2}$: on input $(\trc{x}, \trc{w})$, return $\sem{\DF_2}(\sem{\DT_1}(\trc{x},\trc{w}))$. This can be implemented by converting $\DF_2$ into a DT $\DT_2$ on states $F_1 \cup F_2$ (as in the prefix sum construction), and then simply constructing $\concat{\DT_1}{\DT_2}$. Even if $\DT_2$ is not restartable, we can see directly that on every input, the final states $F_2$ are equal to $\DF_2$ applied to the output of $\DT_1$.
Similarly, if $\DF_1: \DFtype{I_1}{I_2}$ and $\DT_2: \DTtuplesub{2}$, then we may convert $\DF_1$ into a DT $\DT_1$ on states $I_1 \cup I_2$. Then the construction $\concat{\DT_1}{\DT_2}$, on every input $(\trc{x},\trc{w})$, returns $\sem{\DT_2}(\sem{\DF_1}(\trc{x}),\trc{w})$.
We overload the concatenation notation and write these constructions as $\concat{\DT_1}{\DF_2}$ and $\concat{\DF_1}{\DT_2}$. For these constructions, as with prefix sum, we do not write out the extended language of matched strings explicitly.

\begin{figure}[H]
\begin{dtbox}
\textbf{Concatenation with data functions.}
If $\DT_1: \DTtype{I}{Z}$ and $\DF_2: \DFtype{Z}{F}$, then $\concat{\DT_1}{\DF_2} : \DTtype{I}{F}$ implements the semantics
\[
\sem{\concat{\DT_1}{\DF_2}}(\trc{x},\trc{w}) = \sem{\DF_2}(\sem{\DT_1}(\trc{x},\trc{w})),
\]
such that $\size{\concat{\DT_1}{\DF_2}} = \size{\DT_1} + \size{\DF_2} + O(|Z|)$.
Likewise, if $\DF_1: \DFtype{I}{Z}$ and $\DT_2: \DTtype{Z}{F}$, then
$\concat{\DF_1}{\DT_2} : \DTtype{I}{F}$ implements the semantics
\[
\sem{\concat{\DF_1}{\DT_2}}(\trc{x},\trc{w}) =
\sem{\DT_2}(\sem{\DF_1}(\trc{x}),\trc{w}),
\]
such that $\size{\concat{\DF_1}{\DT_2}} = \size{\DF_1} + \size{\DT_2} + O(|Z|)$.
\end{dtbox}

\label{dt:fig:concatenation-with-DF}
\end{figure}

\paragraph*{Iteration}
Now suppose we are given $\DT_1 = \DTtuplesub{1}$, where $I_1$ and $F_1$ are the same up to some bijection. On input $(\trc{x},\trc{w})$, we want to split $\trc{w}$ into $\trc{w}_1 \trc{w}_2 \trc{w}_3 \ldots$, then apply $\sem{\DT_1}(\trc{x},\trc{w}_1)$ to get $\trc{y}_1$, $\sem{\DT_1}(\trc{y}_1,\trc{w}_2)$ to get $\trc{y}_2$, and so on. Then, the answer is the union over all possible ways to write $\trc{w} = \trc{w}_1 \trc{w}_2 \ldots \trc{w}_k$ of $\trc{y}_k$. Let $I$ be a set the same size as $I_1, F_1$ with bijections $\pi: I \to I_1$, $\rho: F \to F_1$. Then we implement this by taking $\DT = \iter{(\DT_1)} = (Q, \Sigma, \Delta, I, I)$ with $Q = Q_1 \cup I$ and
\begin{align*}
\Delta = \Delta_1
    &\cup \big\{(\varepsilon, \{i'\}, \pi(i)', i'): i \in I \big\}
    \cup \big\{(\varepsilon, \{\rho(i)'\}, i', \rho(i)'): i \in I \big\}.
\end{align*}
The idea is again very simple; we have a set of states $I$ that is both initial and final; we always copy the values of these states into the input of $\DT_1$ and copy the final states of $\DT_1$ back into $I$. But the semantics is again more complicated. Here (unlike all other constructions), we do not necessarily preserve acyclicity. When we copy $F_2$ into $I$ and back into $I_2$, this may then propagate back into $F_2$ again. Essentially, if $\DT_1$ produces output on the empty data word, then $\iter{(\DT_1)}$ will always be $\top$, as this will create a cycle with least fixed point $\top$.

We assume that $\DT_1$ is both output-synchronized and restartable. We can write configurations of $\DT$ as $(\trc{c}, \trc{y})$, where $\trc{c}$ is a configuration of $\DT_1$.
On an input word $\trc{w} = (\sigma_1,d_1),\ldots,(\sigma_k,d_k)$, let the sequence of configurations be $(\trc{c}_0, \trc{y}_0)$, $(\trc{c}_1,\trc{y}_1)$, $\ldots$, $(\trc{c}_k, \trc{y}_k)$, so the output of $\DT$ is $\trc{y}_k$.
Then the least-fixed-point semantics of Equation~\eqref{dt:eq:fixpoint-semantics} implies that, for $i=1, \ldots, k$, $\trc{y}_i$ is the least vector satisfying $\trc{y}_i = \left(\update_{\sigma_i, \trc{y}_i}(\trc{c}_{i-1}, d_i)\right)|_{F_1}$. Similarly, for $i = 0$, $\trc{y}_0$ is the least vector satisfying $\trc{y}_0 = \left(\update_{\tg{i}}(\trc{y}_0)\right)|_{F_1}$. Now we want to show by induction that $\trc{c}_i$ simulates the list, over all possible splits of $\trc{w} = \trc{w}_1 \trc{w}_2 \cdots \trc{w}_k$, of the configuration of $\DT_1$ obtained by sequentially applying $\DT_1$ $k$ times. The proof of the inductive step is to take the property $\trc{y}_i = \left(\update_{\sigma_i, \trc{y}_i}(\trc{c}_{i-1}, d_i)\right)|_{F_1}$ and decompose the configuration $\update_{\sigma_i, \trc{y}_i}(\trc{c}_{i-1}, d_i)$ using the simulation relation, and see that it simulates the list of all splits $\trc{w} = \trc{w}_1 \cdots \trc{w}_k$ where $\trc{w}_k$ has size at least 1, plus the additional initialized thread $\update_{\tg{i}}(\trc{y}_i)$.

\begin{figure}[H]
\begin{dtbox}
\textbf{Iteration.}
Let $\DT: \DTtype{I}{I}$ be output-synchronized and restartable.
Then $\iter{\DT}: \DTtype{I}{I}$ satisfies
\[
\sem{\iter{\DT}}(\trc{x},\trc{w})
= \bigsqcup_{\trc{w} = \trc{w}_1 \trc{w}_2 \cdots \trc{w}_k} \sem{\DT}(\ldots \sem{\DT}(\sem{\DT}(\trc{x},\trc{w}_1) ,\trc{w}_2)\ldots,\trc{w}_k),
\]
s.t. $\size{\iter{\DT}} = \size{\DT} + O(|I|)$.
It matches $\clang(\iter{\DT}) = \clang(\DT)^{*}$.
\end{dtbox}

\label{dt:fig:iteration}
\end{figure}

\paragraph*{Properties of restartability.}
All operations except ``support'' preserve restartability.
The ``output-synchronized'' property is also preserved by union, concatenation, and iteration, but is not guaranteed with parallel composition: $\parcompDT{\DT_1}{\DT_2}$ is output-synchronized only if $\clang(\DT_1) = \clang(\DT_2)$.

\begin{theorem}
\label{dt:thm:restartability-preserved}
If $\DT_1$ and $\DT_2$ are restartable, then so
are $\parcompDT{\DT_1}{\DT_2}$ and $\union{\DT_1}{\DT_2}$.
If $\DT_1$ is additionally output-synchronized, then $\concat{\DT_1}{\DT_2}$ and $\iter{\DT_1}$ are restartable.
If $\DT_1$ is restartable and output-synchronized and additionally $\clang(\DT_1) = \Sigma^{*}$, and if $\DF$ is a data function where each output value is given by a single term over the input values, then $\prefixsum{\DT_1}{\DF}$ is restartable.
\end{theorem}
\begin{proof}
For $\parcompDT{\DT_1}{\DT_2}$ and $\union{\DT_1}{\DT_2}$, we represent configurations of the machine has pairs $(\trc{c}_1, \trc{c}_2)$, and we define $(\trc{c}_1, \trc{c}_2) \sim [(\trc{c}_{1,1},\trc{c}_{2,1}),\ldots,(\trc{c}_{1,k},\trc{c}_{2,k})]$ if \emph{both} $\trc{c}_1 \sim [\trc{c}_{1,1},\ldots,\trc{c}_{1,k}]$ and $\trc{c}_2 \sim [\trc{c}_{2,1},\ldots,\trc{c}_{2,k}]$.
For prefix sum, the restartability holds for somewhat trivial reasons: if we restart with only $\vec{\bot}$, the output is $\bot$: if we restart with only one non-$\vec{\bot}$ thread, the output is the prefix-sum, and if we restart with two or more non-$\vec{\bot}$ threads, the output is $\top$ everywhere.
For concatenation, we have configurations that are pairs $(\trc{c}_1, \trc{c}_2)$ of a configuration in $\DT_1$ and one in $\DT_2$. We define $(\trc{c}_1, \trc{c}_2) \sim [(\trc{c}_{1,1},\trc{c}_{2,1}),\ldots,(\trc{c}_{1,k},\trc{c}_{2,k})]$ if $\trc{c}_1 \sim [\trc{c}_{1,1},\ldots,\trc{c}_{1,k}]$ and \emph{there exists} sequences $l_{2,1}$, $l_{2,2}$, $\ldots$, $l_{2,k}$, such that $\trc{c}_{2,i}$ simulates $l_{2,i}$ and $\trc{c}_2$ simulates the entire sequence of sequences, $l_{2,1} \circ l_{2,2} \circ \cdots \circ l_{2,k}$. The idea is that a configuration in $\DT = \concat{\DT_1}{\DT_2}$ simulates a list of configurations where each configuration consists of only a single thread in $\DT_1$, but may have many threads in $\DT_2$ (since one thread in $\DT_1$ may cause $\DT_2$ to be restarted several times). However, we still need that \emph{there exists} some further simulation of the configuration in $\DT_2$ into a set of individual threads, such that the overall configuration of $\DT_2$ in $\DT$ simulates all of these individual threads.
For iteration $\DT = \iter{\DT_1}$, we have to do this recursively. The simulation on $\DT$ includes $\DT_1$ but extends it to the least relation such that whenever $\trc{c}_i \sim [\trc{c}_{i,1}, \ldots, \trc{c}_{i,k}]$ for each $i$, if $\trc{c} \sim [\trc{c}_1, \ldots, \trc{c}_k]$ then $\trc{c} \sim [\trc{c}_{i,j}]_{i,j}$.
\end{proof}

\begin{theorem}
Given a DT $\DT$ as input,
checking if $\DT$ is restartable is PSPACE-complete.
\label{dt:thm:restartable-pspace-complete}
\end{theorem}
\begin{proof}
Construct $\aut{P}$ as in the proof of Theorem~\ref{dt:thm:regular-language}, a DT over $(\trc{u}, \Uops)$ where $\trc{u} = \{\one\}$.
Use $c_i$ and $p_i$ to denote configurations of $\DT$ and $\aut{P}$, respectively.

We first prove a lemma: that $\DT$ is restartable iff $\aut{P}$ is restartable.
The forward direction is immediate:
define the relation $p \sim [p_1, p_2, \ldots, p_k]$
if there exists $c \sim [c_1, c_2, \ldots, c_k]$
such that $p_i$ is the projection of $c_i$ to $\trc{u}$;
then facts (i), (ii), and (iii) are homomorphically preserved.
The backward direction is nontrivial.
We need to define the simulation relation
between configurations and lists of configurations.
We define the \emph{reachable} relation $R \subseteq C \times [C]$
to be the minimal relation that is implied by properties (i) and (ii), i.e. the set of pairs
$(c, [c_1, c_2, \ldots, c_k])$ reachable from initialization followed
by some sequence of updates-with-restarts $\update_{\sigma,\trc{x}}$.
We will show that $R$ is a simulation by showing that
(iii) holds of all reachable pairs.
The key observation---which holds even if
$\DT$ is not restartable---is that for every reachable pair
$(c, [c_1, c_2, \ldots, c_k])$,
$c \ge c_i$ for all $i$ (where $\ge$ is the coordinate-wise partial ordering on data vectors defined in \Cref{dt:subsec:preliminaries}).
This is proven inductively.
% Intuitively, since the operations on $\cdata$ are monotone, re-initializing the initial states
% only increases the resulting configuration.
% We can prove this by induction. The base case (i) is $\vec{\bot} \le \vec{\bot}$.
% For the inductive step (ii), reading in $\Sigma \times D$,
% note that circuits $\update_\sigma$ and $\update_\varepsilon$ are monotone
% (since they compose only monotone operations),
% so $c \ge c_i$ implies
% $\update_\varepsilon(\update_\sigma(c,d)) \ge \update_\varepsilon(\update_\sigma(c_i,d))$.
% For the inductive step (iii),
% note that $c \cup c_I \ge c_I$
% and $c \cup c_I \ge c \ge c_i$.
Using this we claim that $R$ satisfies (iii).
Let $(c, [c_1, c_2, \ldots, c_k])$ be reachable.
Fix $f \in F$.
Since $\aut{P}$ is restartable, we know that
$c(f)$ and $c_1(f) \sqcup \cdots \sqcup c_k(f)$ are either both undefined, both defined, or both conflict.
Thus the only way they can be unequal (violating (iii)) is if they are both in $\data$, and distinct.
If they are both in $\data$, then $c_i(f) = \bot$ for all $i$ except one, say $c_j(f) = d'$.
But from the key observation above, $c(f) \ge c_j(f)$, and since $c(f), c_j(f) \in \data$, we have equality $c(f) \ge c_j(f)$.

We give a coNPSPACE algorithm to check restartability of a DT $\DT$. By the above lemma, it is enough to work with $\aut{P}$ instead.
So we need to check if there exists
a reachable pair $(p, [p_1,\ldots,p_k])$,
where $p$ and $p_i$ are configurations of $\aut{P}$,
such that
$\final(p) = \final(p_1) \sqcup \final(p_2) \sqcup \cdots \sqcup \final(p_k)$.
But choose $k$ to be minimal;
then we do not need to keep track of $p_1, \ldots, p_{k-1}$,
but can instead collapse these into a single configuration $p'$.
Specifically, before the $k$th restart,
suppose we are at $(p', [p_1',p_2',\ldots, p_{k-1}'])$;
then rather than keeping $p_1'$ through $p_{k-1}'$,
we know the output will always be the same as taking $p'$,
so we keep track only of $p'$.
Using this trick, the space required to store
$(p, [p_1, \ldots, p_k])$ is constant: three configurations of $\aut{P}$.
Overall, we guess a sequence of moves to get
to $(p', [p_1', \ldots, p_{k-1}']$,
then guess a sequence of moves to get to $p$ from there,
and guess a place to stop and try checking if
$p(f) = p_1(f) \sqcup p_2(f) \sqcup \cdots \sqcup p_k(f)$ for all $f \in F$.
The total space is bounded and some thread accepts if and only if there is a counterexample,
meaning the machine is not restartable.

PSPACE-hardness can be shown by a reduction from the problem of universality for NFAs.
We carefully exploit that if
NFAs $N_1$ and $N_2$ are translated to DTs which always output $\bot$ or $\top$,
and $\DF$ is a single binary operation,
the DT construction $\concat{(\parcompDT{N_1}{N_2})}{\DF}$ is restartable iff
there do not exist strings $u, v$ such that
$u \in L(N_1)$, $u \notin L(N_2)$, $uv \notin L(N_1)$, $uv \in L(N_2)$, or vice versa.
\end{proof}

\paragraph*{Converting to restartable.}
It is shown in Theorem~\ref{dt:thm:dt-expressiveness} that a DT of size $m$ can be converted to a deterministic CRA of size $\exp(m)$; and that a deterministic CRA of size $m$ can be converted into a \emph{restartable} DT of size $O(m)$. This gives a procedure to convert DT to restartable DT, unfortunately with exponential blowup. Fortunately, Theorem~\ref{dt:thm:restartability-preserved} guarantees that such exponential blowup does not arise in the compilation of the QRE-Past language of \Cref{dt:sec:rm}.

\section{The QRE-Past Monitoring Language}
\label{dt:sec:rm}

In this section we present the \QREpast{} query language for quantitative runtime monitoring (Quantitative Regular Expressions with Past-time temporal operators). Each query compiles to a streaming algorithm, given as a DT, whose evaluation has precise complexity guarantees in the size of the query. Specifically, the complexity is a quadratic number of registers and quadratic number of operations to process each element, in the size of the query, independent of the input stream. Our language employs several constructs from the StreamQRE language \cite{StreamQRE}. To this core set of combinators we add the $\prefsumQ$ operation, $\fillQ$ and $\fillwithQ$ operations, and also past-time temporal logic operators which allow querying temporal safety properties: for example, ``is the average of the last five measurements always more than two standard deviations above the average over the last two days?''
We have picked constructs which we believe to be intuitive to program and useful in the application domains we have studied, but we do not intend them to be exhaustive; there are many other combinators which could be defined, added to the language, and implemented using the back-end support provided by the constructions of \Cref{dt:sec:constructions}.

By compiling to the DT machine model, we show that the compiled code has the same precise complexity guarantee of the code produced by the StreamQRE engine of \cite{StreamQRE}, including the additional temporal operators. Since compiled StreamQRE code was shown to have better throughput than popular existing streaming engines (RxJava, Esper, and Flink) when deployed on a single machine, this is good evidence that \QREpast{} would see similar success with more flexible language constructs.
% In \Cref{dt:subsec:rm-case-study}, we look at how an example policy can be expressed in \QREpast{}.

\subsection{Syntax of QRE-Past}
\label{dt:subsec:rm-syntax}

Expressions in the language are divided into three types: \emph{quantitative queries} of two types, either base-level ($\qq$) or top-level ($\tlqq$), and \emph{temporal queries} ($\tq$). Base-level quantitative queries specify functions from data words to quantities (extended data values $\cdata$), and are compiled to \emph{restartable DTs} with a single initial state and single final state, of quadratic size. These queries are based on StreamQRE and the original Quantitative Regular Expressions of \cite{QRE}. Top-level quantitative queries also specify functions from data words to quantities, but the compiled DT may not be restartable. Temporal queries specify functions from data words to Booleans, may be constructed from quantitative queries, and are compiled to DTs which output Booleans. Temporal queries are based on the operators of past-time temporal logic \cite{manna2012temporal} and informed by successful existing work on monitoring of safety properties \cite{havelund2004efficient}, which adapts to our setting via constructions on DTs.
% (Unlike in model checking, past-time temporal operators are preferred over future-time temporal operators in monitoring, because we must produce an answer on each finite trace.

We model Booleans as elements in $\data$. Thus, we assume that $0, 1 \in \data$, and that $\le, \ge, = \;\in \ops_2$: these are comparison operations on data values returning $0$ or $1$. We also assume that we have Boolean operators $\lnot \in \ops_1$ and $\land, \lor, \to, \leftrightarrow \in \ops_2$,
which treat $0$ as false and every $d \ne 0$ as true.

Each query has an associated regular \emph{rate} $\clang(\qq)$, given by a regular expression on $\Sigma$ defined recursively with the query. The rate expresses the set of strings on which the compiled DT is defined \emph{ or } conflict. For temporal queries $\tq$, the rate is $\Sigma^{*}$. We also may refer to the \emph{language} $\lang(\qq) \subseteq \clang(\qq)$, which is the set of strings on which the compiled DT is defined.
There are a few \emph{typing restrictions}, mainly constraints on the rates of the queries. Because each rate is given by a regular expression, the typing restrictions are \emph{type-checkable} in polynomial time.
The typing restrictions arise in order to guarantee restartability so that the constructions of \Cref{dt:sec:constructions} apply.

\begin{figure}[t]
\centering \small
\begin{align*}
\qq :=
    &\mid \atomQ(\sigma, t)
        &&\{\sigma\}
        &&\sigma \in \Sigma, t \in \tms[\curritem] \\
    &\mid \epsQ(t)
        &&\{\varepsilon\}
        && t \in \tms[\varnothing] \\
    &\mid \orQ(\qq_1,\qq_2)
        &&\clang(\qq_1) \cup \clang(\qq_2) \\
    &\mid \splitQ(\qq_1,\qq_2,\op)
        &&\clang(\qq_1) \cdot \clang(\qq_2)
        &&\op \in \ops_2 \\
    &\mid \iterQ(\qq_1,\initval,\op)
        &&(\clang(\qq_1))^{*}
        &&\initval \in \data, \op \in \ops_2 \\
    &\mid \combineQ(\qq_1,\ldots,\qq_k,\op)
        &&\clang(\qq_1) \cap \cdots \cap \clang(\qq_k)
        &&\op \in \ops_k; \text{ well-typed if } \clang(\qq_1) = \cdots = \clang(\qq_k) \\
    &\mid \prefsumQ(\qq_1,\initval,\op)
        && \Sigma^{*}
        && \initval \in \data, \op \in \ops_2; \text{ well-typed if } \lang(\qq_1) = \Sigma^{*} \\
\tlqq :=
    &\mid \qq_1
        && \clang(\qq_1) \\
    &\mid \fillQ(\qq_1)
        && \lang(\qq_1) \cdot \Sigma^{*} \\
    &\mid \fillwithQ(\qq_1,\qq_2)
        && \lang(\qq_1) \cup \clang(\qq_2)
\end{align*}
\begin{align*}
\tq :=
    &\mid \tlqq_1 \compop \tlqq_2
        &&\Sigma^{*}
        &&\compop \in \{\le, \ge, =\}; \text{ well-typed if } L(\tlqq_1) = L(\tlqq_2) = \Sigma^{*} \qquad\qquad \\
    &\mid \tq_1 \bop \tq_2
    \quad\mid \lnot \tq_1
        &&\Sigma^{*}
        &&\bop \in \{\land,\lor,\to,\leftrightarrow\} \\
    &\mid \prevT \tq_1
    \quad\mid \alwaysT \tq_1
    \quad\mid \eventuallyT \tq_1
        &&\Sigma^{*} \\
    &\mid \tq_1 \sinceWT \tq_2
    \quad\mid \tq_1 \sinceST \tq_2
        &&\Sigma^{*}
\end{align*}

\caption[Summary of the QRE-Past language.]{Summary of the QRE-Past language: syntax for quantitative queries $\qq$, $\tlqq$ and temporal queries $\tq$. The second column gives the rate of the query as a regular expression.
% The third column gives typing restrictions for a particular operator to be applied.
}
\end{figure}

\subsection{Semantics and Compilation Algorithm}
\label{dt:subsec:rm-compilation}

We describe each construction's semantics, and how it is directly implemented as a DT.
For technical reasons, for each quantitative query (\emph{not} for temporal queries) $\qq$ or $\tlqq$ we produce \emph{two} DTs. The first is $\DT_{\qq}: \DTtype{X}{Y}$, where $|X| = |Y| = 1$. The semantics will be such that $\sem{\DT_{\qq}}(x,\trc{w})$ is the value of query $\qq$ on input $\trc{w}$, if $x$ is defined. So $x$ is not really used, except to allow the machine to be restartable (at least one initial state is needed for restarts). The second is $\aut{I}_{\qq}: \DTtype{X}{Y}$, where $|X|=|Y|=1$, which has the following \emph{identity} semantics: $\sem{\aut{I}_{\qq}}(x,\trc{w}) = x$ if $\sem{\DT_{\qq}}(x,\trc{w}) \in \data$, $\top$ if $\sem{\DT_{\qq}}(x,\trc{w}) = \top$, and $\bot$ if $\sem{\DT_{\qq}}(x,\trc{w}) = \bot$.
In particular, $\aut{I}_{\qq}$ is \emph{equivalent} to $\DT_{\qq}$ (definition in \Cref{dt:subsec:dt-regularity}).
We use this second machine $\aut{I}_{\qq}$ to \emph{save} values for using later. For example, to implement $\splitQ(f,g,\op)$ we concatenate the machine for $f$ with a machine which both saves the output of $f$ \emph{and} starts $g$; then when $g$ is finished we combine the saved output of $f$ with the output of $g$ via $\op$. We will guarantee in the translation that $\aut{I}_{\qq}$ has size only linear in the query, but $\DT_{\qq}$ has worst-case quadratic size.

\paragraph*{Atomic expressions: $\atomQ, \epsQ$.}
The atomic expressions are the building blocks of all queries. For $t \in \tms[\curritem]$, the query $\atomQ(\sigma, t)$ matches a data word containing a single character $(\sigma, d)$, and returns $t$ evaluated with $\curritem = d$. Similarly, the query $\epsQ(t)$ matches the empty data word and returns the evaluation of $t$.
Both of these are implementable using a DT with two states, $Q = \{q_i, q_f\}$, with $I = \{q_i\}$ and $F = \{q_f\}$.
$\DT_{\atomQ(\sigma, t)}$ uses one transition from $\{q_i\}$ to $q_f'$ with term $t$, and $\DT_{\epsQ(t)}$ uses an epsilon transition from $\{q_i'\}$ to $q_f'$ with term $t$.
These machines are restartable by a similar argument as the example immediately following Definition~\ref{dt:definition:restartability} (alternatively, if they aren't, just convert to an equivalent restartable DT as in \Cref{dt:subsec:constructions-restartable}, last paragraph).
The definition of $\aut{I}_{\atomQ(\sigma, t)}$ is the same as $\DT_{\atomQ(\sigma, t)}$ except that the term $t$ in the transition is replaced by $q_i$; and likewise for $\aut{I}_{\epsQ(t)}$.

%%% Old explanation -- more detailed
% We define $\DT_{\atomQ(\sigma, t)}$ to have two states: $Q = \{q_i, q_f\}$, with $I = \{q_i\}$ and $F = \{q_f\}$. We define only one transition: $(\sigma, \{q_i\}, q_f', t)$. The result is that whenever we read a $\sigma$, if $q_i$ is defined, then the output $q_f'$ is set to $t$. If we read in any other character, or more than one character, the output will be undefined again. Moreover, this machine is restartable: define $\trc{c} \sim [\trc{c}_1, \ldots, \trc{c}_k]$ whenever $\trc{c} = \bigsqcup_{i=1}^k \trc{c}_i$. Then we see that this is a bisimulation relation between configurations of the machine and a list of copies of configurations of the machine, such that initializing $q_i$ with additional values in $\trc{c}$ is equivalent ($\sim$) to adding new threads with those additional values to the list, and the output of $\trc{c}$ is the union of the outputs of $\trc{c}_i$.

% We define $\DT_{\epsQ(t)}$ with the same $Q, I$, and $F$, but a single epsilon-transition $(\varepsilon, \{q_i'\}, q_f', t)$ (note the $q_i'$ instead of $q_i$, and recall that $\varepsilon$ is an abbreviation for a copy of the transition for every $\sigma \in \Sigma \cup \{{\tg{i}}\}$. In every reachable configuration $\trc{c}$ of the machine, the value of $q_f$ is $\sem{t}(\trc{c}'|_{q_i})$, even with restarts. So we define $\trc{c} \sim [\trc{c}_1, \ldots, \trc{c}_k]$ if $\trc{c}$ and all $\trc{c}_i$ satisfy this, and $\trc{c} = \bigsqcup_{i=1}^k \trc{c}_i$.

% The definition of $\aut{I}_{\atomQ(\sigma, t)}$ is the same as $\DT_{\atomQ(\sigma, t)}$ except that the term $t$ in the transition is replaced by $q_i$; and likewise the definition of $\aut{I}_{\epsQ(t)}$ is the same as $\DT_{\epsQ(t)}$ except the term $t$ in the transition is replaced by $q_i$. The identical argument shows they are restartable.

\paragraph*{Regular operators: $\orQ, \splitQ, \iterQ$.}
These regular operators are like traditional union, concatenation, and iteration (respectively), except that if the parsing of the string (data word) is not unique, the result will be $\top$.
The union operation $\orQ(\qq_1, \qq_2)$ should match every data word that matches either $\qq_1$ or $\qq_2$; if it matches only one, its value is that query, but if it matches both, its value is $\top$. In particular, conflict values ``propagate upwards'' because even if only one of $\qq_1, \qq_2$ matches, if the value is $\top$ then the result is $\top$. This is exactly the semantics of the DT construction $\union{\DT_{\qq_1}}{\DT_{\qq_2}}$. It is restartable because $\DT_{\qq_1}$ and $\DT_{\qq_2}$ are restartable, by Theorem~\ref{dt:thm:restartability-preserved}.
Similarly, we can take $\aut{I}_{\orQ(\qq_1,\qq_2)} = \union{\aut{I}_{\qq_1}}{\aut{I}_{\qq_2}}$.
Both of these constructions add only a constant to the size.

The operation $\splitQ(\qq_1, \qq_2, \op)$ splits a data word $\trc{w}$ into two parts, $\trc{w}_1 \cdot \trc{w}_2$, such that $\trc{w}_1$ matches $\qq_1$ and $\trc{w}_2$ matches $\qq_2$. If there are multiple splits, the result is $\top$; otherwise, the result is $\op(\qq_1(\trc{w}_1),\qq_2(\trc{w}_2))$.
Here, we have to do some work to save the value of $\qq_1(\trc{w}_1)$ in the DT construction. We implement $\splitQ$ as
$\DT_{\splitQ(\qq_1, \qq_2,\op)}
:= \concat{(\concat{\DT_{\qq_1}}{(\parcompDT{\aut{I}_{\qq_2}}{\DT_{\qq_2}})})}{\DF_{\op}},$
where $\DF_{\op}$ is a data function with two inputs $y_1, y_2$ which returns one output $\op(y_1,y_2)$, where $y_1$ is the final state of $\aut{I}_{\qq_2}$ and $y_2$ is the final state of $\DT_{\qq_2}$. Let's parse what this is saying. We split the string $\trc{w}$ into two parts $\trc{w}_1 \cdot \trc{w}_2$ such that $\trc{w}_i \in \clang(\qq_i)$, and apply $\qq_1$ to the first part; for the second part, we have a transducer which takes the output of $\qq_1$ as input and produces both that value as $y_1$, as well as the new output of $\qq_2$ as $y_2$. Then both of these are passed to $\DF_{\op}$ which returns $\op(y_1, y_2)$. To define $\aut{I}_{\splitQ(\qq_1,\qq_2,\op)}$ is easier: we take $\concat{\aut{I}_{\qq_1}}{\aut{I}_{\qq_2}}$.

The operation $\iterQ(\qq_1,\initval,\op)$ splits $\trc{w}$ into $\trc{w}_1 \cdots \trc{w}_k$ such that $\trc{w}_i \in \clang(\qq_1)$ and then \emph{folds} $\op$ over the list of outputs of $\qq_1$, starting from $\initval$, to get a result: for instance if $k=3$, the result is $\op(\op(\op(\initval,\qq_1(\trc{w}_1)),\qq_1(\trc{w}_2)),\qq_1(\trc{w}_3))$. If the parsing is not unique, the result is $\top$. We implement this as
$\DT_{\iterQ(\qq_1,\initval,\op)} :=
\concat{G_{\initval}}{\iter{\left(\concat{(\parcompDT{\aut{I}_{\qq_1}}{\DT_{\qq_1}})}{\DF_{\op}}\right)}}$,
where $G_\initval$ is a data function which outputs the initial value $\initval$.
The idea here is that $\concat{(\parcompDT{\aut{I}_{\qq_1}}{\DT_{\qq_1}})}{\DF_{\op}}$ takes an input, both saves it and performs a new computation $\DT_{\qq_1}$, and then produces $\op$ of the old value and the new value. When this is iterated, we get the desired fold operation.
For $\aut{I}_{\iterQ(\qq_1,\initval,\op)}$ we can simply take $\iter{(\aut{I}_{\qq_1})}$.

We claim that these constructions preserve restartability. For concatenation, we need that the $\parcompDT{}{}$ is output-synchronized: we need that $\DT_{\qq_2}$ and $\aut{I}_{\qq_2}$ have the same rate. This is true by construction: $\aut{I}$ is equivalent to $\DT$ and only differs in that it is the identity function from input to output.
So the three DTs concatenated are all output-synchronized. Restartability is preserved because the data function $\DF_{\op}$ is converted to a restartable DT in the concatenation construction.
The size of the concatenation construction is bounded by a quadratic polynomial because we have added additional size equal to the size of $\aut{I}_{\qq_2}$, which is bounded by a linear polynomial.
For iteration, $\parcompDT{}{}$ is similarly only applied to equivalent DTs, and $\DF_{\op}$ is converted to a restartable DT in concatenation.
As with $\splitQ$, the size of our construction includes the size of $\DT_{\qq_1}$ but adds a linear size due to inclusion of $\aut{I}_{\qq_1}$, so we preserve a quadratic bound on size.
The constructions $\concat{\aut{I}_{\qq_1}}{\aut{I}_{\qq_2}}$
and $\iter{(\aut{I}_{\qq_1})}$ preserve a linear bound and are restartable because $\aut{I}_{\qq_1}$ and $\aut{I}_{\qq_2}$ are restartable.

\paragraph*{Parallel combination: $\combineQ$.}
This is the first operation in our language which requires a typing restriction.
For $\combineQ(\qq_1, \ldots, \qq_k, \op)$, the computation is simple: apply every $\qq_i$
to the input stream to get a result, then \emph{combine} all these results via operation $\op$.
The implementation as a DT is
$\DT_{\combineQ(\qq_1, \ldots, \qq_k, \op)} := \concat{\left(\parcompDT{\DT_{\qq_1}}{\parcompDT{\cdots}{\DT_{\qq_k}}}\right)}{\DF_\op}$,
where $\DF_\op$ applies $\op$ to the $k$ final states of the $\parcompDT{}{}$.
For $\aut{I}_{\combineQ(\qq_1,\ldots, \qq_k, \op)}$, we do the same thing but replace $\op$ by the term $y_1$ (i.e. we use $\DF_{y_1} : \DFtype{\{y_1,\ldots,y_k\}}{\{y\}}$ where $y$ is the final output variable).
The construction for $\combineQ$ is well-defined even if the typing restriction is not satisfied, but does not preserve restartability in that case. We use the non-restartable version in some other constructions.
If the typing restriction \emph{is} satisfied, then this exactly states that the left part of the concatenation is output-synchronized, and given that the right data function is converted to a restartable DT, restartability is preserved.
The size of both $\DT_{\combineQ(\qq_1, \ldots, \qq_k, \op)}$ and $\aut{I}_{\combineQ(\qq_1,\ldots, \qq_k, \op)}$ are linear in the sizes of the constituent DTs, so these constructions preserve the quadratic and linear bound on size, respectively.

\paragraph*{Prefix sum: $\prefsumQ$.}
The prefix sum $\prefsumQ(\qq_1,\initval,\op)$ is defined only if $\qq_1$ is defined (not conflict) on all input. Its value should be $\op(\initval,\qq_1(\varepsilon))$ on the empty string, and then fold $\op$ over the outputs of $\qq_1$ after that. This is implemented directly using the prefix-sum constructor.
\[
\DT_{\prefsumQ(\qq_1,\initval,\op)} :=
    \concat{G_{\initval,\initval}}{\left(\prefixsum{\DT_{\qq_1}}{\DF_\op}\right)}.
\]
Here, $G_{\initval,\initval}$ is a data function to return two copies of $\initval$. We need two copies because $\DT_{\qq_1}$ has one initial state, which needs an initial value (anything in $\data$ would work just as well).
% It can be seen that $\parcompDT{\DT_{\epsQ(\initval)}}{\DT_{\epsQ(\initval)}}$ is equivalent to the DT obtained from a data function which returns $(\initval, \initval)$, so this concatenation is concatenation with a data function.
% Restartability is preserved by applying the theorem directly.

\paragraph*{Fill operations: $\fillQ, \fillwithQ$.}
These operations are ways to \emph{fill in} the values which are $\bot$ and $\top$ with other values. This will not preserve restartability, so it is only allowed in top-level queries; however, it is useful to do this in order to get a query defined on all input data words, so that comparison $\tlqq_1 \compop \tlqq_2$ can be applied.
The query $\fillQ(\qq_1)$ always returns the \emph{last} defined value returned by $\qq_1$. For instance, if the sequence of outputs of $\qq_1$ is $\bot, \top, 3, \top, 4, 5, \bot$, the outputs of $\fillQ(\qq_1)$ should be $\bot, \bot, 3, 3, 4, 5, 5$.
The query $\fillwithQ(\qq_1,\qq_2)$, instead of outputting the last defined value returned by $\qq_2$, just outputs the value returned by $\qq_2$ if $\qq_1$ is not defined. So, if $\qq_2$ is the constant always returning $0$, the sequence of outputs of $\fillwithQ(\qq_1,\qq_2)$ should be $0, 0, 3, 0, 4, 5, 0$.

To accomplish these constructions, we first obtain two DTs $\DT_{+}$ and $\DT_{-}$ which are defined when $\qq_1$ is defined and when $\qq_1$ is not defined, respectively:
$\DT_{+} = \isdef{\aut{I}_{\qq_1}}$ and
$\DT_{-} = \union{\isbot{\aut{I}_{\qq_1}}}{\istop{\aut{I}_{\qq_1}}}$.
Here, $\isbot{}{}$ and $\istop{}{}$ have quadratic blowup, but because we use $\aut{I}$ in the argument to those constructions instead of $\DT$, $\DT_{+}$ and $\DT_{-}$ only have quadratic size. Now, let $\text{fst},\text{snd}: \data^2 \to \data$ be the first and second projection operations. Then we implement the fill operations as:
\begin{align*}
\fillwithQ(\qq_1,\qq_2)
    &:= \union{\combineQ(\DT_{\qq_1}, \DT_{+}, \text{fst})}{\combineQ(\DT_{\qq_2}, \DT_{-}, \text{fst})} \\
\fillQ(\qq_1)
    &:= \prefixsum{\left(\parcompDT{\combineQ(\DT_{\qq_1}, \DT_{+}, \text{fst})}{\DT_{-}}\right)}{\DF},
\end{align*}
where $\DF$ is a data function which expresses how to update the fill result based on the previous fill result, and whether $\DT_{\qq_1}$ is defined or not: if defined, we should take the new defined value, and otherwise, we should take the old fill result.

\paragraph*{Comparison: $\le, \ge, =$.}
The semantics of $\tlqq_1 \compop{} \tlqq_2$ is just to apply $\compop$: for example if $\compop$ is $<$, and if $y_1$ and $y_2$ are the outputs of $\tlqq_1$ and $\tlqq_2$ (which are always defined), then $\tlqq_1 < \tlqq_2$ should output $y_1 < y_2$ (which is $0$ or $1$). Therefore, this construction can be implemented as $\combineQ(\tlqq_1, \tlqq_2, \compop)$. We do not need to worry about restartability for temporal queries, and we also don't define $\aut{I}$.

\paragraph*{Boolean operators: $\land, \lor, \to, \leftrightarrow, \lnot$.}
Similarly, the Boolean operators are implemented by applying the corresponding operation.
For example, $\tq_1 \lor \tq_2$ is implemented as $\combineQ(\tq_1,\tq_2,\lor)$.

\paragraph*{Past-temporal operators: $\prevT, \alwaysT, \eventuallyT, \sinceWT, \sinceST{}$.}
% Finally, we have the past temporal operators.
These have the usual semantics on finite traces: for example $\prevT(\tq_1)$ says that $\tq_1$ was true at the previous item, and is false initially, and $\eventuallyT(\tq_1)$ says that $\tq_1$ was true at some point in the trace up to this point (including at the present time). The implementation of $\prevT$ uses concatenation while the others all use prefix sum. Define $\DT_{\prevT(\tq_1)} := \concat{\DT_{\tq_1}}{\aut{I}_{\Sigma}}$, where we define $\aut{I}_{\Sigma}$ to be a DT which matches any data word of length 1, and has the identity semantics (returns the initial value as output). This concatenation is defined because $\aut{I}_{\Sigma}$ is restartable; it has the correct semantics because $\prevT$ means to look at the prefix of the input except the last character.
For the $\prefsumQ$ temporal operators, we illustrate only the example of $\eventuallyT(\tq_1)$; the other cases are similar. Define a data function $\DF$ which computes the truth value of $\eventuallyT(\tq_1)$ on input $\trc{w} (\sigma, d)$ given its truth value on $\trc{w}$ and given the truth value of $\tq_1$ on input $\trc{w} (\sigma, d)$ (so, $G$ is just disjunction). Define $\DT_{\eventuallyT(\tq_1)} := \concat{G_{0,0}}{\prefixsum{\DT_{\tq_1}}{\DF}}$, where $G_{0,0}$ is a data function outputting two copies of $0$ (false) to initialize the computation.

\paragraph*{Complexity of QRE-Past evaluation.}
Our implementations give us the following theorem. In particular, combining with Theorem~\ref{dt:thm:dt-eval}, the evaluation of any query on an input data stream requires quadratically many registers and quadratically many operations per element, independent of the length of the stream.

\begin{theorem}
For every well-typed base-level quantitative query $\qq$, the compilation described above via the constructions of \Cref{dt:sec:constructions} produces a restartable DT $\DT_\qq$ of quadratic size in the length of the query. For every well-typed top-level quantitative query $\tlqq$ or temporal query $\tq$, the compilation produces a DT of quadratic size which implements the semantics.
\label{dt:thm:quadratic}
\end{theorem}

\section{Succinctness}
\label{dt:sec:succinctness}

\subsection{Comparison with Cost Register Automata}
\label{dt:subsec:dts-and-cras}

Cost register automata (CRAs) were introduced in \cite{AdADRY2013CRA} as a machine-based characterization of the class of \emph{regular transductions}, which is a notion of regularity that relies on the theory of MSO-definable string-to-tree transductions. One advantage of CRAs over other approaches is that they suggest an obvious algorithm for computing the output in a streaming manner. A CRA has a finite-state control that is updated based only on the tag values of the input data word, and a finite set of write-only registers that are updated at each step using the given operations. The original CRA model is a deterministic machine, whose registers can hold data values as well as functions represented by terms with parameters. Each register update is required to be \emph{copyless}, that is, a register can appear at most once
in the right-hand-side expressions of the updates.

In \citeMain{tcs20}, the class of \emph{Streamable Regular} ($\mathsf{SR}$) transductions is introduced, which has two equivalent characterizations: in terms of MSO-definable string-to-dag (directed acyclic graph) transductions without backward edges, and in terms of \emph{possibly copyful} CRAs. Since the focus is on streamability, and terms can grow linearly with the size of the input stream, the registers are restricted to hold only values, not terms. This CRA model is expressively equivalent to DTs.

\begin{theorem}
\label{dt:thm:dt-expressiveness}
The class of transductions computed by data transducers is equal to the class $\mathsf{SR}$.
\end{theorem}
\begin{proof}[Proof sketch]
It suffices to show semantics-preserving translations from (unambiguously nondeterministic, copyful) CRAs to DTs and vice versa. Suppose $\aut A$ is an unambiguous CRA with states $Q$ and registers $X$. We construct a DT $\aut B$ with states $Q \times X$. In the other direction, suppose $\aut A = \DTtuple$ is a DT. We construct a deterministic CRA $\aut B$ with states $\{\bot,\one,\top\}^Q$ and variables $Q$. A configuration of $\aut B$ consists of a state in $\{\bot,\one,\top\}^Q$ and an assignment $\data^Q$, and therefore uniquely specifies a configuration of $\aut A$. For each state in $\aut B$ and each $\sigma$, the transition to the next state can be determined from the set of transitions $\update_\sigma$ in $\aut A$.
% can then be modeled with one $\sigma$-labeled transitions in $\aut B$ from each state.
% (convert to acyclic and expand out an expression for each $q' \in Q$ as a term in $\tms[Q]$).
\end{proof}

However, DTs---even restartable DTs---are exponentially more succinct than (unambiguously nondeterministic, copyful) CRAs.
The succinct modular constructions on DTs are not possible on CRAs. For example, the parallel composition of CRAs requires a product construction, whereas the parallel composition of DTs employs a disjoint union construction ($\parcompDT{}{}$). This is why multiple parallel compositions of CRAs can cause an exponential blowup of the state space, but the corresponding construction on DTs causes only a linear increase in size.

\begin{theorem}
For some $(\data, \ops)$, (restartable) DTs can be exponentially more succinct than CRAs.
\end{theorem}
\begin{proof}[Proof sketch]
Let $\Sigma = \{\sigma_1, \ldots, \sigma_k\}$, $\data = \mathbb{N}$, and $\ops = \{+\}$ (addition). Suppose that $\aut A_i$ for $i=1,\ldots,k$ is a DT that outputs the sum of all values if the input contains $\sigma_i$, and $0$ otherwise. Notice that $\aut A_i$ can be implemented with two state variables. Now, $\aut A$ is the restartable DT with $O(k)$ states that adds the results of $\aut A_1$, \ldots, $\aut A_k$. A CRA that implements the same function as $\aut A$ needs finite control that remembers which tags have appeared so far. This implies that the CRA needs exponentially many states, and this is true even if unambiguous nondeterminism is allowed.
\end{proof}

\subsection{Comparison with Finite-State Automata}
\label{dt:subsec:dts-and-fsa}

Another perspective on succinctness is to compare DTs with finite automata for expressing regular languages.
To simplify this, consider DTs over a singleton data set $\data = \{\one\}$, with no initial states and one final state. Each such DT $\DT$ computes a regular language $\clang(\DT)$.
If we further restrict to \emph{acyclic} DTs, they are exactly as succinct as \emph{reversed alternating finite automata} (r-AFA). In particular, this implies that acyclic DTs (and hence DTs) are exponentially more succinct than  DFAs and NFAs.

An r-AFA \cite{chandra1981alternation,salomaa2000efficient} consists of $(Q, \Sigma, \delta, I, F)$ where the transition function $\delta$ assigns to each state in $Q$ a \emph{Boolean combination} of the previous values of $Q$. For example, we could assign $\delta(q_3) = q_1 \land (q_2 \lor \lnot q_3)$. An r-AFA is equivalent to an AFA where the input string is read in the opposite order.
The translation from DT to r-AFA copies the states, and on each update, sets each state to be equal to the disjunction of the transitions into it, where each transition is the conjunction of the source variables. Thus, the total size of $\delta$ is bounded by the size of the DT.
For the other direction, we first remove negation in the standard way; then, conjunction becomes $\op$ and disjunction becomes $\sqcup$ (multiple transitions with a single target) in the DT.

It is known \cite{chandra1981alternation,fellah1990constructions} that $L$ is recognized by a r-AFA with $n$ states if and only if it is recognized by a DFA with $2^n$ states. This gives an exponential gap in state complexity between acyclic DTs and finite automata, both DFAs and NFAs. To see the gap for NFAs, consider a DFA with $2^n$ states which has no equivalent NFA with a fewer number of states. Acyclic DTs are a special case, so DTs are exponentially more succinct than both DFAs (uniformly) and NFAs (in the worst case).

\subsection{Comparison with General Stream-Processing Programs}
\label{dt:subsec:dts-and-spp}

% FROM INTRO
%To gain a better understanding of the expressiveness and succinctness of DTs, consider a (generic) streaming algorithm that maintains a fixed number of Boolean and data variables, and processes each data item by updating these variables by executing a loop-free code. While such algorithms capture {\em all} streaming computations, the class of all streaming computations is not suitable for modular specifications. For instance,  consider quantitative concatenation operation: given transductions $f$ and $g$, and a binary data operation {\textit{op}}, $h={\tt split}(f,g,{\textit{op}})$ splits the inputs stream $w$ uniquely into two parts $w=w_1w_2$ and returns $h(w)={\textit{op}}(f(w_1),g(w_2))$. While the class of streamable regular transductions is closed under this operation, the class of all streaming algorithms is not.  We can enforce regularity of a generic streaming algorithm by requiring, for instance, that the updates to the Boolean variables are not influenced by the values of the data variables. We show that streaming algorithms with these restrictions can be translated to DTs without any blow-up, thus establishing that DTs are the most succinct (upto a constant factor) representation of streamable regular transductions. The structure of a DT---as variables ranging over data/undefined/conflict values and update code as a set of transitions of a particular form, as opposed to traditional loop-free update code, not only enforces regularity, but is also what allows us to define succinct constructions  on the representation.

Finally, we consider a general model of computation for efficient streaming algorithms. The algorithm's maintained state consists of a fixed number of Boolean variables (in $\{0,1\}$) and data variables (in $\data$), where the Boolean variables support all Boolean operations, but the data variables can only be accessed or modified using operations in $\ops$. The behavior of the algorithm is given by an \emph{initialization} function, an \emph{update} function, a distinguished \emph{output} data variable and a Boolean output flag (which is set to indicate output is present). The initialization and update functions are specified using a \emph{loop-free} imperative language with the following constructs: assignments to Boolean or data variables, sequential composition, and conditionals. This model captures all efficient (bounded space and per-element processing time) streaming computations over a set of allowed data operations $\ops$. We write $\textsc{Stream}(\ops)$ to denote the class of such efficient streaming algorithms. The problem with the class $\textsc{Stream}(\ops)$ is that it is not suitable for modular specifications. As the following theorem shows, it is not closed under the $\splitQ$ combinator.

\begin{theorem}
\label{dt:thm:nonRegular}
Let $\Sigma = \{a,b\}$, $\data = \mathbb{N}$, and let $\ops$ be the family of operations that includes unary increment, unary decrement, the constant $0$, and the binary equality predicate. Define the transductions $f, g: (\Sigma \times \data)^{*} \to \data \cup \{\bot\}$ as follows:
\begin{align*}
L(f) &= \{ w \in \Sigma^{*} \;:\; |w|_a = 2 \cdot |w|_b \}
&
L(g) &= \{ w \in \Sigma^{*} \;:\; |w|_a = |w|_b \}
\\
f(\trc{w}) &= \begin{cases}
  1, &\text{if $\trc{w} \downarrow \Sigma \in L(f)$} \\
  \bot, &\text{otherwise}
\end{cases}
&
g(\trc{w}) &= \begin{cases}
  1, &\text{if $\trc{w} \downarrow \Sigma \in L(g)$} \\
  \bot, &\text{otherwise}
\end{cases}
\end{align*}
where $|w|_a$ is notation for the number of $a$'s that appear in $w$. Both $f$ and $g$ are streamable functions (i.e. are computable in $\textsc{Stream}(\ops)$), but $h = \splitQ(f, g, (x,y) \mapsto 1)$ is not.
\end{theorem}
\begin{proof}[Proof]
Both $f$ and $g$ can be implemented efficiently by maintaining two counters for the number of $a$'s and the number of $b$'s seen so far.
On the other hand, any streaming algorithm that computes $h$ requires a linear number of bits (in the size of the stream seen so far). Specifically, consider the behavior of such a streaming algorithm on inputs of the form $a(aab | aba)^n ab$. On these $2^n$ distinct inputs, each of length $3n+3$, the streaming algorithm would have to reach $2^n$ different internal states, because the inputs are pairwise distinguished by reading in a further string of the form $b^k$. Thus on inputs of size $O(n)$ the streaming algorithm requires at least $n$ bits to store the state.
Any streaming algorithm in $\textsc{Stream}(\ops)$, however, employs a finite number of integer registers whose size (in bits) can grow only logarithmically.
\end{proof}

Theorem~\ref{dt:thm:nonRegular} suggests that some restriction on the domains of transductions is necessary in order to maintain closure under modular constructions. We therefore enforce \emph{regularity} of a generic streaming algorithm by requiring that the values of the Boolean variables depend solely on the input tags. That is, they do not depend on the input data values or the values of the data variables. Under this restriction, a streaming algorithm can be encoded as a DT of roughly the same size.

\begin{theorem}
A streaming algorithm of $\textsc{Stream}(\ops)$ that satisfies the regularity restriction can be implemented by a DT over $\ops$. This construction can be performed in linear time and space.
\end{theorem}
\begin{proof}[Proof sketch]
Consider an arbitrary streaming algorithm of $\textsc{Stream}(\ops)$ that satisfies the regularity restriction. Each data variable is encoded as a DT state that is always defined. Each Boolean variable $b$ is encoded using two DT states $x_b$ and $x_{\bar b}$ as follows: if $b = 0$ then $x_b = \bot$ and $x_{\bar b} = d_\one$, and if $b = 1$ then $x_b = d_\one$ and $x_{\bar b} = \bot$, where $d_\one$ is some fixed element of $\data$.
\end{proof}

\section{Discussion}
\label{dt:sec:discussion}

The original paper did not report on an implementation, but we implemented data transducers later as a library in Rust
and it is available \githubref{https://github.com/cdstanford/data-transducers}{on GitHub}.
One direction for future work is to apply this library for either streaming operator performance bounds, query optimization, or both.

The end goal is something like this: part of the library allows writing
a query using a distributed variant of quantitative regular expressions.
The query is then compiled to Timely with an input and output synchronization schema derived from the query as part of the dataflow representation above.

While this allows for ordering guarantees, one question is how to then derive performance guarantees for the operator as data transducer performance is only \emph{up to} the cost of base operations on the base data types.
One possible approach is a combination of empirical and analytical information: using the state machine representation we can calculate an analytical space and time bound for processing items,
and then using empirical testing we can derive running time bounds for the operators in the graph.
Another approach would be to define an abstract notion of latency and throughput in number of steps only (without the empirical component),
and use this to derive logical verification conditions related to number of state updates required to process a single input item for each operator (latency),
and number of state updates that can be processed in parallel (throughput).

% Data transducers are a succinct, implementation-level machine model for general streaming computations.
% They combine finite control (active vs. inactive states) and
% register updates (e.g. in CRAs) into one integrated model, with \emph{state variables} that can be
% undefined, defined, or conflicted.
% All DTs admit streaming evaluation (Theorem~\ref{dt:thm:dt-eval}), but in order to additionally support modular constructions, we identified an equally-expressive subclass of \emph{restartable DTs}.
% We showed that DTs admit succinct \emph{union, concatenation, iteration, parallel composition, prefix-sum, and support} constructions (\Cref{dt:sec:constructions}), where restartability is required for concatenation and iteration.
%
% Although converting a DT to a restartable DT may involve exponential blowup, we showed that because the constructions preserve restartability (Theorem~\ref{dt:thm:restartability-preserved}), such blowup does not arise in the modular compilation of realistic queries using DTs. To illustrate this point, we proposed a query language called \QREpast{}, which combines elements of StreamQRE \cite{StreamQRE} with past-time temporal logic operators \cite{havelund2004efficient}, such that all queries compile modularly to quadratic-size DTs via the succinct constructions.
%
% We formally justified that DTs are exponentially more succinct over CRAs (\Cref{dt:subsec:dts-and-cras}), and that they relate to a certain kind of finite automata and are more succinct than DFAs and NFAs (\Cref{dt:subsec:dts-and-fsa}). In fact, we showed that DTs are as succinct as general streaming computations, where the update function is specified using loop-free code, and a \emph{regularity restriction} is enforced (\Cref{dt:subsec:dts-and-spp}). Without such a restriction, general streaming computations are not closed under concatenation (Theorem~\ref{dt:thm:nonRegular}).

One notable operation missing from our constructions in \Cref{dt:sec:constructions} is that of \emph{sequential composition}, in which we pass the sequence of outputs of one machine as the input stream to another. This operation is crucial to many applications, has been included in some previous presentations of QREs \cite{QRE, StreamQRE},
and should be considered in future implementations of this work. We omitted it here because it introduces notational complexity: in order to define sequential composition, both the input and output streams need to be tagged (not just the input stream), and (at least) the final states of a DT need to be associated with output tags.

% In future work, we hope to explore opportunities for query optimization using the DT model. The DT framework lends itself more easily to this purpose than QREs or unstructured streaming algorithms. In the case of NFAs, bisimulation relations can be used to reduce the size of the automata via a quotient construction, and it seems plausible that an analogous notion can be defined for DTs to reduce the number of variables. The Java implementation of the StreamQRE language (reported in \cite{StreamQRE}) does not currently use DTs, and could benefit from such optimizations.
